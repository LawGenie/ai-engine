from openai import OpenAI
from typing import List, Dict, Any
from config import settings
import json
import logging

logger = logging.getLogger(__name__)

class LLMService:
    def __init__(self):
        self.client = OpenAI(api_key=settings.openai_api_key)
        self.model = settings.graph_model
    
    async def generate_reasoning(self, 
                               product_name: str, 
                               product_description: str,
                               candidates: List[Dict[str, Any]],
                               origin_country: str = "KOR") -> Dict[str, str]:
        """í›„ë³´ë³„ ì¶”ì²œ ì´ìœ  ìƒì„± (HS ë¶„ë¥˜ ê·œì¹™ ê¸°ë°˜, í•œêµ­ì–´ ë²ˆì—­ í¬í•¨)"""
        
        if not candidates:
            return {}
        
        # í›„ë³´ ì •ë³´ ì¤€ë¹„ - Combined description ì‚¬ìš©
        from vector_service import VectorService
        vector_service = VectorService()
        
        candidate_list = []
        for c in candidates:
            # Combined description ê°€ì ¸ì˜¤ê¸°
            hierarchical_desc = vector_service.get_hierarchical_description(c["hts_number"])
            combined_description = hierarchical_desc.get("combined_description", c["description"])
            
            candidate_list.append({
                "hsCode": c["hts_number"],
                "hsDescription": c["description"],  # ì›ë³¸ ì„¤ëª…ë„ ìœ ì§€
                "hierarchicalDescription": combined_description,  # Combined description ì¶”ê°€
                "confidenceScore": c["similarity"]
            })
        
        # í•œêµ­ì–´ ì „ìš© í”„ë¡¬í”„íŠ¸ - ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ìƒì„±
        prompt = f"""ë‹¹ì‹ ì€ ë¯¸êµ­ HS ì½”ë“œ ë¶„ë¥˜ ì „ë¬¸ê°€ë¡œì„œ êµ­ì œë¬´ì—­ ê·œì •ê³¼ ê´€ì„¸ ë¶„ë¥˜ì— ëŒ€í•œ ê¹Šì€ ì§€ì‹ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.

ë¶„ë¥˜ ì‹œ ê³ ë ¤ì‚¬í•­:
1. ì œí’ˆì˜ ì¬ì§ˆê³¼ ì œì¡° ê³µì • (ë¬´ì—‡ìœ¼ë¡œ ë§Œë“¤ì–´ì¡ŒëŠ”ê°€?)
2. ì£¼ìš” ìš©ë„ì™€ ê¸°ëŠ¥ (ì–´ë–»ê²Œ ì‚¬ìš©ë˜ëŠ”ê°€?)
3. HS ì½”ë“œ ê³„ì¸µêµ¬ì¡°: ë¥˜(Chapter) â†’ í˜¸(Heading) â†’ ì†Œí˜¸(Subheading)
4. ì¼ë°˜í•´ì„ê·œì¹™(GIR) ì ìš©
5. ì›ì‚°ì§€êµ­({origin_country})ì˜ ê´€ì„¸ ìµœì í™” ê³ ë ¤
6. íŠ¹ë³„ ë¬´ì—­í˜‘ì • (í•œêµ­ ì œí’ˆì˜ ê²½ìš° í•œë¯¸FTA)

ë¶„ë¥˜í•  ì œí’ˆ:
- ì œí’ˆëª…: {product_name}
- ì œí’ˆ ì„¤ëª…: {product_description}
- ì›ì‚°ì§€: {origin_country}

í›„ë³´ HS ì½”ë“œë“¤ (ë²¡í„° ìœ ì‚¬ë„ ìˆœ):
{json.dumps(candidate_list, indent=2)}

ê° í›„ë³´ ì½”ë“œì— ëŒ€í•´ ë‹¤ìŒ 4ë‹¨ê³„ë¡œ ë…¼ë¦¬ì  ì„¤ëª…ì„ ì œê³µí•˜ì„¸ìš”:

1. ì œí’ˆ ë¶„ì„: ì´ ì œí’ˆì´ ë¬´ì—‡ì´ë©° í•µì‹¬ íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€
2. ë¶„ë¥˜ ê·¼ê±°: ì¬ì§ˆ/ìš©ë„/ê¸°ëŠ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì™œ ì´ HS ì½”ë“œê°€ ì ìš©ë˜ëŠ”ê°€
3. êµ¬ë³„ ìš”ì†Œ: ë‹¤ë¥¸ ìœ ì‚¬ ì½”ë“œë“¤ê³¼ ë¹„êµí–ˆì„ ë•Œ ì´ ì½”ë“œê°€ ë” ì í•©í•œ ì´ìœ 
4. ì‹ ë¢°ë„ í‰ê°€: ì–¼ë§ˆë‚˜ í™•ì‹¤í•œì§€ì™€ ê·¸ ì´ìœ 

JSON ë°°ì—´ë¡œ ì¶œë ¥ (í•œêµ­ì–´ ì¶”ì²œê·¼ê±°ë§Œ):
[
  {{
    "hsCode": "ì½”ë“œ",
    "reasoning": "ë…¼ë¦¬ì  4ë‹¨ê³„ ì„¤ëª… (4-5 ë¬¸ì¥). ì œí’ˆì˜ êµ¬ì²´ì  íŠ¹ì§•ê³¼ ì„±ë¶„ì„ ì–¸ê¸‰í•˜ê³ , ì™œ ì´ ì½”ë“œê°€ ë‹¤ë¥¸ ì½”ë“œë³´ë‹¤ ì í•©í•œì§€ ëª…í™•í•œ ê·¼ê±° ì œì‹œ. ì˜ˆ: 'ì´ í¬ë¦¼ì€ íˆì•Œë£¨ë¡ ì‚° ì„±ë¶„ìœ¼ë¡œ ë³´ìŠµì´ ì£¼ëª©ì ì…ë‹ˆë‹¤', 'ë¦½ìŠ¤í‹±ê³¼ ë‹¬ë¦¬ í”¼ë¶€ì— í¡ìˆ˜ë˜ëŠ” í˜•íƒœì…ë‹ˆë‹¤' ë“± êµ¬ì²´ì  ë¹„êµ í¬í•¨"
  }}
]

ì¤‘ìš”ì‚¬í•­:
1. ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„± (ë²ˆì—­ì²´ ê¸ˆì§€)
2. êµ¬ì²´ì  ì œí’ˆ íŠ¹ì„±(ì„±ë¶„, í˜•íƒœ, ê¸°ëŠ¥)ì„ ê·¼ê±°ë¡œ ì‚¬ìš©
3. ìœ ì‚¬ ì½”ë“œì™€ ë¹„êµí•˜ì—¬ ì°¨ì´ì  ëª…ì‹œ (ì˜ˆ: "ë¦½ìŠ¤í‹± ì½”ë“œì™€ ë‹¬ë¦¬", "ì„¸ì •ì œì™€ ë‹¤ë¥´ê²Œ")
4. ë¶„ë¥˜ ê²°ì •ì— ì˜í–¥ì„ ì¤€ êµ¬ì²´ì  ìš”ì†Œ ì–¸ê¸‰
5. ëª¨í˜¸í•œ í‘œí˜„ ê¸ˆì§€ - êµ¬ì²´ì  ê·¼ê±° ê¸°ë°˜ ì„œìˆ 
6. ê° HS ì½”ë“œë³„ë¡œ ê³ ìœ í•œ êµ¬ë³„ ìš”ì†Œ ì œì‹œ
7. JSON ë°°ì—´ë§Œ ì¶œë ¥, ì¶”ê°€ ì„¤ëª… ê¸ˆì§€"""

        try:
            # íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ LLM í˜¸ì¶œ (ë” ê¸´ ì‘ë‹µì„ ìœ„í•´ max_tokens ì¦ê°€)
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                max_tokens=1500,  # ì´ì¤‘ ì–¸ì–´ ì‘ë‹µì„ ìœ„í•´ ì¦ê°€
                timeout=30.0  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
            )
            
            text = response.choices[0].message.content or "[]"
            logger.info(f"ğŸ¤– LLM raw response: {text[:200]}...")
            
            # JSON ì¶”ì¶œ
            start = text.find("[")
            end = text.rfind("]") + 1
            
            if start != -1 and end != -1:
                json_str = text[start:end]
                reasoning_list = json.loads(json_str)
                
                # í•œêµ­ì–´ ì¶”ì²œê·¼ê±° ì§ì ‘ ë°˜í™˜
                return {
                    item.get("hsCode", ""): item.get("reasoning", "")
                    for item in reasoning_list
                    if isinstance(item, dict)
                }
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSON parsing failed: {e}")
            logger.error(f"Raw response: {text}")
        except Exception as e:
            logger.error(f"âŒ LLM reasoning generation failed: {e}")
        
        # í´ë°±: ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ê¸°ë³¸ ì„¤ëª…
        return {
            c["hts_number"]: f"ì´ ì œí’ˆì€ {product_name}ë¡œ ë¶„ì„ë©ë‹ˆë‹¤. {c['description'][:30]}... ë¶„ë¥˜ì— ê°€ì¥ ì í•©í•œ ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤. ì œí’ˆì˜ íŠ¹ì„±ê³¼ ìš©ë„ë¥¼ ê³ ë ¤í•  ë•Œ ì´ HS ì½”ë“œê°€ ì ì ˆí•©ë‹ˆë‹¤. ë‹¤ë¥¸ ìœ ì‚¬ ì½”ë“œë“¤ë³´ë‹¤ ì œí’ˆ íŠ¹ì§•ê³¼ ì˜ ë§ì•„ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë¶„ë¥˜ì…ë‹ˆë‹¤."
            for c in candidates
        }