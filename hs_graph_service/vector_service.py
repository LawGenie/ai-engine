import json
import faiss
import numpy as np
from pathlib import Path
from typing import List, Dict, Any, Optional
from config import settings
import logging

logger = logging.getLogger(__name__)

class VectorService:
    def __init__(self):
        self.index_path = Path(settings.vector_index_path) / "hts_index.faiss"
        self.metadata_path = Path(settings.vector_index_path) / "metadata.json"
        
        # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
        self.index = faiss.read_index(str(self.index_path))
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        with open(self.metadata_path, 'r', encoding='utf-8') as f:
            self.metadata = json.load(f)
        
        # HTS ë²ˆí˜¸ë¡œ ë¹ ë¥¸ ì¡°íšŒë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
        self.hts_lookup = {
            record.get("hts_number"): record
            for record in self.metadata
            if record.get("hts_number")
        }
        
        # ì „ì²´ HTS ë°ì´í„° ë¡œë“œ (ê³„ì¸µì  ì„¤ëª…ì„ ìœ„í•´)
        self._load_full_hts_data()
        
        logger.info(f"Vector service initialized with {len(self.metadata)} records")
        logger.info(f"HTS lookup dictionary has {len(self.hts_lookup)} entries")
    
    def _load_full_hts_data(self):
        """ì „ì²´ HTS ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ê³„ì¸µì  ì„¤ëª… ì¡°íšŒ ê°€ëŠ¥í•˜ê²Œ í•¨"""
        try:
            full_data_path = Path(settings.vector_index_path).parent / "data" / "hts_complete_data.json"
            with open(full_data_path, 'r', encoding='utf-8') as f:
                self.full_hts_data = json.load(f)
            
            # ê³„ì¸µë³„ ì¡°íšŒë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬ êµ¬ì„±
            self.full_hts_lookup = {}
            
            for record in self.full_hts_data:
                hts_number = record.get("hts_number", "")
                if hts_number:
                    self.full_hts_lookup[hts_number] = record
            
            logger.info(f"Full HTS data loaded: {len(self.full_hts_data)} records")
            
        except Exception as e:
            logger.error(f"Failed to load full HTS data: {e}")
            self.full_hts_data = []
            self.full_hts_lookup = {}
    
    
    def get_hierarchical_description(self, hts_number: str) -> Dict[str, str]:
        """HS ì½”ë“œì˜ ê³„ì¸µì  ì„¤ëª… ë°˜í™˜ (Heading-Subheading-Tertiary Subheading)"""
        if not hts_number or len(hts_number) < 10:
            return {"error": "Invalid HTS number"}
        
        try:
            # 10ìë¦¬ HS ì½”ë“œì—ì„œ ê³„ì¸µ ì¶”ì¶œ
            heading = hts_number[:4]  # 4ìë¦¬ (ì˜ˆ: 3304)
            
            # 8ìë¦¬ subheading ì°¾ê¸° (ì  ì œê±°)
            hts_clean = hts_number.replace('.', '')
            subheading_8 = hts_clean[:6]  # 6ìë¦¬ (ì˜ˆ: 330499)
            
            # Heading ì„¤ëª… (4ìë¦¬)
            heading_desc = ""
            if heading in self.full_hts_lookup:
                heading_desc = self.full_hts_lookup[heading].get("description", "")
            
            # Subheading ì„¤ëª… (6ìë¦¬) - ë‹¤ì–‘í•œ í˜•íƒœë¡œ ì‹œë„
            subheading_desc = ""
            possible_subheadings = [
                f"{heading}.{subheading_8[4:6]}",  # 3304.99
                f"{heading}.{subheading_8[4:6]}.00",  # 3304.99.00
                subheading_8,  # 330499
            ]
            
            for sub_code in possible_subheadings:
                if sub_code in self.full_hts_lookup:
                    subheading_desc = self.full_hts_lookup[sub_code].get("description", "")
                    break
            
            # Tertiary Subheading ì„¤ëª… (10ìë¦¬ - í˜„ì¬ ì½”ë“œ)
            tertiary_desc = ""
            if hts_number in self.full_hts_lookup:
                tertiary_desc = self.full_hts_lookup[hts_number].get("description", "")
            elif hts_number in self.hts_lookup:
                tertiary_desc = self.hts_lookup[hts_number].get("description", "")
            
            # ê³„ì¸µì  ì„¤ëª… ì¡°í•© - ì˜ë¯¸ìˆëŠ” ì„¤ëª…ë“¤ë§Œ ì—°ê²°
            combined_descriptions = []
            
            if heading_desc and heading_desc.strip():
                combined_descriptions.append(f"Heading ({heading}): {heading_desc.rstrip(':')}")
            
            if subheading_desc and subheading_desc.strip() and subheading_desc.lower() != "other":
                combined_descriptions.append(f"Subheading: {subheading_desc.rstrip(':')}")
            
            if tertiary_desc and tertiary_desc.strip():
                if tertiary_desc.lower() == "other" and len(combined_descriptions) > 0:
                    # "Other"ì¸ ê²½ìš° ìƒìœ„ ì„¤ëª…ê³¼ ì¡°í•©
                    combined_descriptions.append("Other preparations in this category")
                else:
                    combined_descriptions.append(f"Specific: {tertiary_desc}")
            
            # ìµœì¢… ì¡°í•©ëœ ì„¤ëª…
            final_description = " â†’ ".join(combined_descriptions) if combined_descriptions else f"HS Code {hts_number}"
            
            return {
                "heading": f"{heading_desc.rstrip(':')}" if heading_desc else f"Heading {heading}",
                "subheading": f"{subheading_desc.rstrip(':')}" if subheading_desc else f"Subheading {subheading_8}",
                "tertiary": f"{tertiary_desc.rstrip(':')}" if tertiary_desc else f"Code {hts_number}",
                "combined_description": final_description,
                "heading_code": heading,
                "subheading_code": subheading_8,
                "tertiary_code": hts_number
            }
            
        except Exception as e:
            logger.error(f"Error getting hierarchical description for {hts_number}: {e}")
            return {"error": f"Failed to get hierarchical description: {e}"}
    
    def _hash_embedding(self, text: str, dim: int = 384) -> List[float]:
        """ê°œì„ ëœ í•´ì‹œ ì„ë² ë”© - ì˜ë¯¸ì  ìœ ì‚¬ì„± ê°•í™”"""
        vector = [0.0] * dim
        if not text:
            return vector
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ - ì˜ë¯¸ì  í† í° ì¶”ì¶œ
        processed_text = self._preprocess_for_embedding(text)
        
        # ë‹¨ì–´ ë‹¨ìœ„ í•´ì‹± (ê¸°ì¡´ ë¬¸ì ë‹¨ìœ„ë³´ë‹¤ ì˜ë¯¸ì )
        words = processed_text.split()
        for word_idx, word in enumerate(words):
            word_hash = hash(word.lower()) % dim
            # ë‹¨ì–´ ìœ„ì¹˜ì™€ ë¹ˆë„ ê³ ë ¤
            position_weight = 1.0 / (word_idx + 1)  # ì•ìª½ ë‹¨ì–´ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
            vector[word_hash] += position_weight
            
            # ë¬¸ì ë‹¨ìœ„ë„ ë³´ì¡°ì ìœ¼ë¡œ ì‚¬ìš© (ê¸°ì¡´ ë°©ì‹)
            for char_idx, ch in enumerate(word):
                bucket = (ord(ch) + char_idx * 1315423911 + word_idx * 7919) % dim
                vector[bucket] += 0.3  # ë‚®ì€ ê°€ì¤‘ì¹˜
        
        # L2 ì •ê·œí™”
        norm = sum(v * v for v in vector) ** 0.5
        if norm > 0:
            vector = [v / norm for v in vector]
        
        return vector
    
    def _preprocess_for_embedding(self, text: str) -> str:
        """ì„ë² ë”©ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ê°„ì†Œí™”)"""
        import re
        
        # ì†Œë¬¸ì ë³€í™˜
        text = text.lower()
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±°
        text = re.sub(r'[^\w\s]', ' ', text)
        
        # ì—°ì† ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def _is_10_digit_hts(self, hts_number: str) -> bool:
        """10ìë¦¬ HS ì½”ë“œì¸ì§€ í™•ì¸ (XXXX.XX.XX.XX í˜•íƒœ)"""
        if not hts_number:
            return False
        
        # ì ì„ ì œê±°í•˜ê³  ìˆ«ìë§Œ í™•ì¸
        digits_only = hts_number.replace('.', '')
        
        # ì •í™•íˆ 10ìë¦¬ ìˆ«ìì¸ì§€ í™•ì¸
        if len(digits_only) == 10 and digits_only.isdigit():
            return True
        
        # XXXX.XX.XX.XX í˜•íƒœì¸ì§€ í™•ì¸
        parts = hts_number.split('.')
        if len(parts) == 4:
            try:
                # ê° ë¶€ë¶„ì´ ì˜¬ë°”ë¥¸ ê¸¸ì´ì˜ ìˆ«ìì¸ì§€ í™•ì¸
                return (len(parts[0]) == 4 and parts[0].isdigit() and
                        len(parts[1]) == 2 and parts[1].isdigit() and
                        len(parts[2]) == 2 and parts[2].isdigit() and
                        len(parts[3]) == 2 and parts[3].isdigit())
            except:
                return False
        
        return False
    
    
    
    def _calculate_combined_similarity(self, query_lower: str, combined_description: str, category_keywords: List[str]) -> float:
        """Combined descriptionê³¼ ì¿¼ë¦¬ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚° (ë²”ìš©ì  ì ‘ê·¼)"""
        if not combined_description:
            return 0.0
        
        desc_lower = combined_description.lower()
        score = 0.0
        
        # 1. ì§ì ‘ í‚¤ì›Œë“œ ë§¤ì¹­ (ì¿¼ë¦¬ì˜ ë‹¨ì–´ë“¤ì´ ì„¤ëª…ì— í¬í•¨ë˜ëŠ”ì§€)
        query_words = set(query_lower.split())
        desc_words = set(desc_lower.split())
        
        # ê³µí†µ ë‹¨ì–´ ë¹„ìœ¨
        common_words = query_words.intersection(desc_words)
        if query_words:
            word_overlap_score = len(common_words) / len(query_words)
            score += word_overlap_score * 0.4
        
        # 2. ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ë§¤ì¹­
        category_matches = sum(1 for kw in category_keywords if kw in desc_lower)
        if category_matches > 0:
            category_score = min(category_matches / len(category_keywords), 0.5)
            score += category_score * 0.3
        
        # 3. ì˜ë¯¸ì  í‚¤ì›Œë“œ ë§¤ì¹­ (í™”ì¥í’ˆ/ì‹í’ˆ ê³µí†µ)
        semantic_keywords = {
            'preparation': 0.2, 'preparations': 0.2,
            'beauty': 0.15, 'cosmetic': 0.15, 'makeup': 0.15,
            'food': 0.15, 'edible': 0.15, 'dietary': 0.15,
            'skin': 0.1, 'care': 0.1, 'treatment': 0.1,
            'other': 0.05  # ì¼ë°˜ì ì¸ "Other" ì¹´í…Œê³ ë¦¬
        }
        
        for keyword, weight in semantic_keywords.items():
            if keyword in desc_lower:
                score += weight
        
        # 4. ì œí’ˆ í˜•íƒœ/íŠ¹ì„± ë§¤ì¹­
        product_forms = {
            'serum': ['serum', 'essence', 'treatment', 'concentrate'],
            'cream': ['cream', 'moisturizer', 'lotion', 'emulsion'],
            'oil': ['oil', 'essential', 'extract'],
            'powder': ['powder', 'dust', 'granule'],
            'liquid': ['liquid', 'solution', 'suspension']
        }
        
        for form_type, form_keywords in product_forms.items():
            if form_type in query_lower:
                form_matches = sum(1 for kw in form_keywords if kw in desc_lower)
                if form_matches > 0:
                    score += min(form_matches * 0.1, 0.2)
        
        return min(score, 1.0)
    
    def _extract_tariff_rate(self, record: Dict[str, Any]) -> float:
        """ë ˆì½”ë“œì—ì„œ ê´€ì„¸ìœ¨ ì¶”ì¶œ (í¼ì„¼íŠ¸ ë‹¨ìœ„ë¡œ ë°˜í™˜)"""
        rate = record.get("final_rate_for_korea", 0.0)
        
        # Noneì´ë‚˜ ë¹ˆ ê°’ ì²˜ë¦¬
        if rate is None or rate == "":
            return 0.0
        
        try:
            rate_float = float(rate)
            # ì´ë¯¸ í¼ì„¼íŠ¸ í˜•ì‹ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return rate_float
        except (ValueError, TypeError):
            logger.warning(f"Invalid tariff rate: {rate}")
            return 0.0
    
    def get_tariff_rate(self, hts_number: str) -> float:
        """HTS ì½”ë“œì˜ ìµœì¢… ê´€ì„¸ìœ¨ ë°˜í™˜ (í¼ì„¼íŠ¸ ë‹¨ìœ„)"""
        # ë¹ ë¥¸ ì¡°íšŒ
        record = self.hts_lookup.get(hts_number)
        
        if record:
            tariff_rate = self._extract_tariff_rate(record)
            logger.info(f"Found tariff for {hts_number}: {tariff_rate}%")
            return tariff_rate
        
        # ëª» ì°¾ì€ ê²½ìš°
        logger.warning(f"HTS number not found: {hts_number}")
        return 0.0
    
    def _direct_keyword_search(self, query: str, top_k: int) -> List[Dict[str, Any]]:
        """ë‹¤ì¤‘ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ê¸°ë°˜ ì§ì ‘ ê²€ìƒ‰ - ì˜ë¯¸ì  ë§¤ì¹­ ê°•í™”"""
        query_lower = query.lower()
        results = []
        
        # 1. ê°„ì†Œí™”ëœ ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ì •ì˜ (ë²”ìš©ì  ì ‘ê·¼)
        categories = {
            'cosmetic': {
                'keywords': [
                    'cosmetic', 'beauty', 'makeup', 'skincare', 'skin', 'facial', 'face',
                    'serum', 'cream', 'lotion', 'toner', 'essence', 'moisturizer', 'cleanser',
                    'anti-aging', 'hydrating', 'nourishing', 'treatment', 'preparation'
                ],
                'chapters': ['33']  # Chapter 33: Essential oils and cosmetic preparations
            },
            'food': {
                'keywords': [
                    'food', 'edible', 'nutrition', 'dietary', 'supplement', 'extract',
                    'preparation', 'cooked', 'instant', 'ready', 'preserved', 'fermented',
                    'cereal', 'grain', 'vegetable', 'sauce', 'condiment', 'seasoning'
                ],
                'chapters': ['04', '19', '20', '21', '22']  # Food-related chapters
            }
        }
        
        # 2. ì¿¼ë¦¬ì—ì„œ ì¹´í…Œê³ ë¦¬ ê°ì§€ (ë‹¤ì¤‘ ì¹´í…Œê³ ë¦¬ ì§€ì›)
        detected_categories = []
        category_scores = {}
        
        for cat_name, cat_info in categories.items():
            keyword_matches = sum(1 for kw in cat_info['keywords'] if kw in query_lower)
            if keyword_matches > 0:
                detected_categories.append(cat_name)
                category_scores[cat_name] = keyword_matches / len(cat_info['keywords'])
        
        # 3. ê°ì§€ëœ ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰
        for category in detected_categories:
            cat_info = categories[category]
            
            for record in self.metadata:
                hts_number = record.get("hts_number", "")
                description = record.get("description", "").lower()
                
                # í•´ë‹¹ Chapterì— ì†í•˜ëŠ”ì§€ í™•ì¸
                if any(hts_number.startswith(ch) for ch in cat_info['chapters']):
                    # 10ìë¦¬ HS ì½”ë“œë§Œ ì²˜ë¦¬ (XXXX.XX.XX.XX í˜•íƒœ)
                    if not self._is_10_digit_hts(hts_number):
                        continue
                    
                    # Combined description ê°€ì ¸ì˜¤ê¸°
                    hierarchical_desc = self.get_hierarchical_description(hts_number)
                    combined_description = hierarchical_desc.get("combined_description", description)
                    
                    # Combined descriptionê³¼ ì¿¼ë¦¬ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚° (ë‹¨ìˆœí™”)
                    similarity_score = self._calculate_combined_similarity(query_lower, combined_description, cat_info['keywords'])
                    
                    # ì¹´í…Œê³ ë¦¬ ì‹ ë¢°ë„ ë°˜ì˜
                    final_score = similarity_score * (0.7 + 0.3 * category_scores[category])
                    
                    if final_score > 0.2:
                        logger.info(f"Combined similarity for {hts_number}: {final_score:.3f} ('{combined_description[:80]}...')")
                        
                        # ì¤‘ë³µ ì œê±° (ë” ë†’ì€ ì ìˆ˜ë§Œ ìœ ì§€)
                        existing = next((r for r in results if r["hts_number"] == hts_number), None)
                        if existing:
                            if final_score > existing["similarity"]:
                                existing["similarity"] = min(final_score, 1.0)
                                existing["category"] = category
                        else:
                            results.append({
                                "hts_number": hts_number,
                                "description": record.get("description", ""),
                                "similarity": min(final_score, 1.0),
                                "final_rate_for_korea": record.get("final_rate_for_korea", 0.0),
                                "category": category
                            })
        
        # 4. ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        results.sort(key=lambda x: x["similarity"], reverse=True)
        return results[:top_k]
    
    def _vector_search_fallback(self, query: str, top_k: int) -> List[Dict[str, Any]]:
        """ê°œì„ ëœ ë²¡í„° ê²€ìƒ‰ - ì˜ë¯¸ì  í™•ì¥ ì¿¼ë¦¬ í™œìš©"""
        # 1. ì˜ë¯¸ì  í™•ì¥ ì¿¼ë¦¬ ìƒì„±
        expanded_query = self._expand_query_semantically(query)
        
        # 2. í™•ì¥ëœ ì¿¼ë¦¬ë¡œ ì„ë² ë”© ìƒì„±
        query_embedding = self._hash_embedding(expanded_query)
        query_vector = np.array([query_embedding], dtype="float32")
        faiss.normalize_L2(query_vector)
        
        # 3. ë” ë„“ì€ ë²”ìœ„ì—ì„œ ê²€ìƒ‰
        search_k = min(top_k * 8, len(self.metadata))
        scores, indices = self.index.search(query_vector, search_k)
        
        results = []
        for score, idx in zip(scores[0], indices[0]):
            if idx < 0 or idx >= len(self.metadata):
                continue
                
            record = self.metadata[idx]
            hts_number = record.get("hts_number", "")
            
            # 10ìë¦¬ HS ì½”ë“œë§Œ ì²˜ë¦¬
            if not self._is_10_digit_hts(hts_number):
                continue
            
            # 4. ì˜ë¯¸ì  ìœ ì‚¬ì„± ì ìˆ˜ ê³„ì‚°
            semantic_score = self._calculate_semantic_similarity(query, record.get("description", ""))
            
            # 5. ë²¡í„° ì ìˆ˜ì™€ ì˜ë¯¸ì  ì ìˆ˜ ì¡°í•©
            combined_score = 0.4 * float(score) + 0.6 * semantic_score
            
            results.append({
                "hts_number": hts_number,
                "description": record.get("description", ""),
                "similarity": combined_score,
                "final_rate_for_korea": record.get("final_rate_for_korea", 0.0),
                "category": "vector_search"
            })
        
        return results
    
    def _expand_query_semantically(self, query: str) -> str:
        """ì¿¼ë¦¬ë¥¼ ì˜ë¯¸ì ìœ¼ë¡œ í™•ì¥ (ê°„ì†Œí™”)"""
        query_lower = query.lower()
        
        # í•µì‹¬ ë™ì˜ì–´ë§Œ ì¶”ê°€
        if 'serum' in query_lower:
            return f"{query} essence treatment"
        elif 'cream' in query_lower:
            return f"{query} lotion moisturizer"
        elif 'perfume' in query_lower:
            return f"{query} fragrance"
        elif 'food' in query_lower:
            return f"{query} edible"
        
        return query
    
    def _calculate_semantic_similarity(self, query: str, description: str) -> float:
        """ì˜ë¯¸ì  ìœ ì‚¬ì„± ê³„ì‚° (ê°„ì†Œí™”)"""
        if not description:
            return 0.0
        
        query_words = set(query.lower().split())
        desc_words = set(description.lower().split())
        
        # ë‹¨ì–´ ì¤‘ë³µë„ (Jaccard similarity)
        intersection = query_words.intersection(desc_words)
        union = query_words.union(desc_words)
        
        return len(intersection) / len(union) if union else 0.0
    
    def _combine_results(self, direct_results: List[Dict], vector_results: List[Dict]) -> List[Dict]:
        """ê²°ê³¼ í†µí•© ë° ì¤‘ë³µ ì œê±°"""
        seen_codes = set()
        combined = []
        
        # ì§ì ‘ ê²€ìƒ‰ ê²°ê³¼ ìš°ì„  (33ë¥˜)
        for result in direct_results:
            hts_code = result["hts_number"]
            if hts_code not in seen_codes:
                seen_codes.add(hts_code)
                combined.append(result)
        
        # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ë³´ì™„ (ì¤‘ë³µ ì œê±°)
        for result in vector_results:
            hts_code = result["hts_number"]
            if hts_code not in seen_codes:
                seen_codes.add(hts_code)
                combined.append(result)
        
        return combined
    
    def search_similar(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        """Combined description ê¸°ë°˜ ê²€ìƒ‰ (ê°„ì†Œí™”)"""
        # 1ë‹¨ê³„: í‚¤ì›Œë“œ ê¸°ë°˜ ì§ì ‘ ê²€ìƒ‰ (ì£¼ìš” ë°©ë²•)
        direct_results = self._direct_keyword_search(query, top_k * 2)
        
        # 2ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ë³´ì™„ (í•„ìš”ì‹œ)
        if len(direct_results) < top_k:
            vector_results = self._vector_search_fallback(query, top_k)
            combined_results = self._combine_results(direct_results, vector_results)
        else:
            combined_results = direct_results
        
        # 3ë‹¨ê³„: ê³„ì¸µì  ì„¤ëª… ì¶”ê°€ ë° ìµœì¢… ì •ë ¬
        final_results = []
        for result in combined_results[:top_k]:
            hierarchical_desc = self.get_hierarchical_description(result["hts_number"])
            
            final_results.append({
                "hts_number": result["hts_number"],
                "description": result["description"],
                "similarity": result["similarity"],
                "final_rate_for_korea": result.get("final_rate_for_korea", 0.0),
                "hierarchical_description": hierarchical_desc
            })
        
        # ê°„ì†Œí™”ëœ ë¡œê¹…
        logger.info(f"ğŸ† Final results: {len(final_results)} HS codes")
        for i, result in enumerate(final_results, 1):
            logger.info(f"  #{i}: {result['hts_number']} (score: {result['similarity']:.3f})")
        
        return final_results
    
    
    