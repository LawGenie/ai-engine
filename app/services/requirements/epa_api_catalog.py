#!/usr/bin/env python3
"""
EPA API ì¹´íƒˆë¡œê·¸ ìë™ ìˆ˜ì§‘ ë° ê´€ë¦¬ ì‹œìŠ¤í…œ
- EPA ê³µì‹ API ëª©ë¡ì„ ìë™ìœ¼ë¡œ ìˆ˜ì§‘
- ê° APIì˜ ì—”ë“œí¬ì¸íŠ¸ì™€ ë¬¸ì„œë¥¼ íŒŒì‹±
- ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ì—¬ ë™ì  ê´€ë¦¬
"""

import asyncio
import httpx
import json
import re
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from pathlib import Path

@dataclass
class EPAAPIDefinition:
    """EPA API ì •ì˜ í´ë˜ìŠ¤"""
    name: str
    description: str
    base_url: str
    endpoints: List[str]
    documentation_url: str
    category: str
    requires_api_key: bool
    rate_limit: str
    last_updated: datetime

class EPAAPICatalog:
    """EPA API ì¹´íƒˆë¡œê·¸ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.catalog_file = Path("epa_api_catalog.json")
        self.apis: Dict[str, EPAAPIDefinition] = {}
        self.load_catalog()
    
    def load_catalog(self):
        """ê¸°ì¡´ ì¹´íƒˆë¡œê·¸ ë¡œë“œ"""
        if self.catalog_file.exists():
            try:
                with open(self.catalog_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for name, api_data in data.items():
                        self.apis[name] = EPAAPIDefinition(
                            name=api_data['name'],
                            description=api_data['description'],
                            base_url=api_data['base_url'],
                            endpoints=api_data['endpoints'],
                            documentation_url=api_data['documentation_url'],
                            category=api_data['category'],
                            requires_api_key=api_data['requires_api_key'],
                            rate_limit=api_data['rate_limit'],
                            last_updated=datetime.fromisoformat(api_data['last_updated'])
                        )
                print(f"âœ… EPA API ì¹´íƒˆë¡œê·¸ ë¡œë“œë¨: {len(self.apis)}ê°œ API")
            except Exception as e:
                print(f"âŒ ì¹´íƒˆë¡œê·¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.apis = {}
    
    def save_catalog(self):
        """ì¹´íƒˆë¡œê·¸ ì €ì¥"""
        data = {}
        for name, api in self.apis.items():
            data[name] = {
                'name': api.name,
                'description': api.description,
                'base_url': api.base_url,
                'endpoints': api.endpoints,
                'documentation_url': api.documentation_url,
                'category': api.category,
                'requires_api_key': api.requires_api_key,
                'rate_limit': api.rate_limit,
                'last_updated': api.last_updated.isoformat()
            }
        
        with open(self.catalog_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ EPA API ì¹´íƒˆë¡œê·¸ ì €ì¥ë¨: {self.catalog_file}")
    
    async def discover_epa_apis(self):
        """EPA ê³µì‹ í˜ì´ì§€ì—ì„œ API ëª©ë¡ ìë™ ë°œê²¬"""
        print("ğŸ” EPA API ìë™ ë°œê²¬ ì‹œì‘...")
        
        # EPA ê³µì‹ API í˜ì´ì§€ ìŠ¤í¬ë˜í•‘
        epa_api_urls = [
            "https://www.epa.gov/data/application-programming-interface-api",
            "https://api.data.gov/docs/",
            "https://catalog.data.gov/organization/epa-gov"
        ]
        
        discovered_apis = []
        
        async with httpx.AsyncClient(timeout=30) as client:
            for url in epa_api_urls:
                try:
                    print(f"ğŸ“¡ ìŠ¤í¬ë˜í•‘: {url}")
                    response = await client.get(url)
                    response.raise_for_status()
                    
                    # HTMLì—ì„œ API ì •ë³´ ì¶”ì¶œ
                    apis = self._extract_apis_from_html(response.text, url)
                    discovered_apis.extend(apis)
                    
                except Exception as e:
                    print(f"âŒ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ {url}: {e}")
        
        # ë°œê²¬ëœ APIë“¤ì„ ì¹´íƒˆë¡œê·¸ì— ì¶”ê°€
        for api_info in discovered_apis:
            if api_info['name'] not in self.apis:
                self.apis[api_info['name']] = EPAAPIDefinition(
                    name=api_info['name'],
                    description=api_info['description'],
                    base_url=api_info['base_url'],
                    endpoints=api_info['endpoints'],
                    documentation_url=api_info['documentation_url'],
                    category=api_info['category'],
                    requires_api_key=api_info['requires_api_key'],
                    rate_limit=api_info['rate_limit'],
                    last_updated=datetime.now()
                )
                print(f"â• ìƒˆ API ë°œê²¬: {api_info['name']}")
        
        self.save_catalog()
        return discovered_apis
    
    def _extract_apis_from_html(self, html: str, source_url: str) -> List[Dict[str, Any]]:
        """HTMLì—ì„œ API ì •ë³´ ì¶”ì¶œ"""
        apis = []
        
        # EPA API ëª©ë¡ íŒ¨í„´ ë§¤ì¹­
        api_patterns = [
            r'<li[^>]*>([^<]*API[^<]*)</li>',
            r'<h[1-6][^>]*>([^<]*API[^<]*)</h[1-6]>',
            r'href="([^"]*api[^"]*)"',
            r'href="([^"]*\.gov[^"]*)"'
        ]
        
        for pattern in api_patterns:
            matches = re.findall(pattern, html, re.IGNORECASE)
            for match in matches:
                if 'api' in match.lower():
                    api_info = self._parse_api_info(match, source_url)
                    if api_info:
                        apis.append(api_info)
        
        return apis
    
    def _parse_api_info(self, text: str, source_url: str) -> Optional[Dict[str, Any]]:
        """API ì •ë³´ íŒŒì‹±"""
        # ê°„ë‹¨í•œ íŒŒì‹± ë¡œì§ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•˜ê²Œ êµ¬í˜„ í•„ìš”)
        if 'api' not in text.lower():
            return None
        
        return {
            'name': text.strip(),
            'description': f"EPA API discovered from {source_url}",
            'base_url': self._guess_base_url(text),
            'endpoints': [],
            'documentation_url': source_url,
            'category': 'environmental',
            'requires_api_key': True,
            'rate_limit': '1000/hour'
        }
    
    def _guess_base_url(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ê¸°ë³¸ URL ì¶”ì¸¡"""
        # URL íŒ¨í„´ ë§¤ì¹­
        url_pattern = r'https?://[^\s<>"]+'
        urls = re.findall(url_pattern, text)
        if urls:
            return urls[0]
        
        # EPA ë„ë©”ì¸ ì¶”ì¸¡
        if 'air' in text.lower():
            return 'https://aqs.epa.gov/data/api'
        elif 'water' in text.lower():
            return 'https://watersgeo.epa.gov/arcgis/rest/services'
        elif 'chemical' in text.lower():
            return 'https://comptox.epa.gov/dashboard/api'
        else:
            return 'https://api.data.gov'
    
    def get_api_for_hs_code(self, hs_code: str) -> List[EPAAPIDefinition]:
        """HS ì½”ë“œì— ì í•©í•œ API ëª©ë¡ ë°˜í™˜"""
        suitable_apis = []
        
        # HS ì½”ë“œ ê¸°ë°˜ API ë§¤ì¹­
        hs_chapter = hs_code[:2]
        
        # í™”í•™ë¬¼ì§ˆ ê´€ë ¨ (28-38ì¥)
        if hs_chapter in ['28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38']:
            for api in self.apis.values():
                if any(keyword in api.name.lower() for keyword in ['chemical', 'toxics', 'pesticide']):
                    suitable_apis.append(api)
        
        # ë†ì‚°ë¬¼ ê´€ë ¨ (01-24ì¥)
        elif hs_chapter in ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24']:
            for api in self.apis.values():
                if any(keyword in api.name.lower() for keyword in ['air', 'water', 'environmental']):
                    suitable_apis.append(api)
        
        # ì „ìì œí’ˆ ê´€ë ¨ (84-85ì¥)
        elif hs_chapter in ['84', '85']:
            for api in self.apis.values():
                if any(keyword in api.name.lower() for keyword in ['air', 'environmental']):
                    suitable_apis.append(api)
        
        return suitable_apis
    
    def get_all_apis(self) -> Dict[str, EPAAPIDefinition]:
        """ëª¨ë“  API ë°˜í™˜"""
        return self.apis
    
    def add_custom_api(self, name: str, base_url: str, description: str = "", category: str = "custom"):
        """ì‚¬ìš©ì ì •ì˜ API ì¶”ê°€"""
        self.apis[name] = EPAAPIDefinition(
            name=name,
            description=description,
            base_url=base_url,
            endpoints=[],
            documentation_url="",
            category=category,
            requires_api_key=True,
            rate_limit="1000/hour",
            last_updated=datetime.now()
        )
        self.save_catalog()
        print(f"â• ì‚¬ìš©ì ì •ì˜ API ì¶”ê°€: {name}")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
epa_catalog = EPAAPICatalog()

async def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    catalog = EPAAPICatalog()
    
    # EPA API ìë™ ë°œê²¬
    discovered = await catalog.discover_epa_apis()
    print(f"ğŸ” ë°œê²¬ëœ API: {len(discovered)}ê°œ")
    
    # HS ì½”ë“œë³„ ì í•©í•œ API ì°¾ê¸°
    test_hs_codes = ["8471.30.01", "3304.99.00", "0101.21.00"]
    for hs_code in test_hs_codes:
        suitable_apis = catalog.get_api_for_hs_code(hs_code)
        print(f"ğŸ“‹ HS {hs_code}ì— ì í•©í•œ API: {len(suitable_apis)}ê°œ")
        for api in suitable_apis:
            print(f"  - {api.name}: {api.base_url}")

if __name__ == "__main__":
    asyncio.run(main())
