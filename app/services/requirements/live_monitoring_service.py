"""
ì‹¤ì‹œê°„ ê·œì • ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤
Federal Register ë° ê¸°ê´€ë³„ ê³µì§€ì‚¬í•­ ëª¨ë‹ˆí„°ë§
"""

import asyncio
import aiohttp
try:
    import feedparser
    HAS_FEEDPARSER = True
except ImportError:
    print("âš ï¸ feedparser íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ RSS í”¼ë“œ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    feedparser = None
    HAS_FEEDPARSER = False
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
import json
from datetime import datetime, timedelta
import re

@dataclass
class RegulationUpdate:
    """ê·œì • ì—…ë°ì´íŠ¸ ì •ë³´"""
    title: str
    agency: str
    publication_date: datetime
    effective_date: Optional[datetime]
    summary: str
    url: str
    impact_level: str  # "low", "medium", "high", "critical"
    affected_hs_codes: List[str]
    change_type: str  # "new", "amendment", "repeal", "clarification"

@dataclass
class MonitoringResult:
    """ëª¨ë‹ˆí„°ë§ ê²°ê³¼"""
    hs_code: str
    product_name: str
    updates_found: List[RegulationUpdate]
    last_check: datetime
    next_check_recommended: datetime
    alert_level: str  # "none", "low", "medium", "high", "critical"

class LiveMonitoringService:
    """ì‹¤ì‹œê°„ ê·œì • ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.rss_feeds = self._build_rss_feeds()
        self.monitoring_keywords = self._build_monitoring_keywords()
        self.update_cache = {}  # ìºì‹œ: hs_code -> last_check_time
    
    def _build_rss_feeds(self) -> Dict[str, str]:
        """RSS í”¼ë“œ URL ì •ì˜"""
        return {
            "federal_register": "https://www.federalregister.gov/api/v1/documents.rss",
            "fda_news": "https://www.fda.gov/news-events/press-announcements/rss.xml",
            "usda_news": "https://www.usda.gov/news/rss",
            "epa_news": "https://www.epa.gov/newsreleases/rss",
            "cpsc_news": "https://www.cpsc.gov/Newsroom/RSS",
            "fcc_news": "https://www.fcc.gov/news/rss"
        }
    
    def _build_monitoring_keywords(self) -> Dict[str, List[str]]:
        """HSì½”ë“œë³„ ëª¨ë‹ˆí„°ë§ í‚¤ì›Œë“œ"""
        return {
            "3304": ["cosmetic", "skincare", "beauty", "serum", "cream", "FDA cosmetic"],
            "3307": ["perfume", "fragrance", "toilet water", "alcohol content"],
            "2106": ["dietary supplement", "ginseng", "health supplement", "DSHEA"],
            "1904": ["rice", "cereal", "prepared food", "instant", "nutritional labeling"],
            "1905": ["snack", "cracker", "cookie", "baker", "FALCPA"],
            "1902": ["pasta", "noodle", "instant", "ramen", "sodium"],
            "2005": ["vegetable", "kimchi", "fermented", "preserved", "HARPC"],
            "8471": ["computer", "electronic", "device", "equipment", "FCC"],
            "8517": ["telephone", "communication", "wireless", "radio", "EMC"],
            "6109": ["clothing", "textile", "garment", "flammability"],
            "9503": ["toy", "children", "play", "game", "safety standards"]
        }
    
    async def monitor_regulation_updates(
        self, 
        hs_code: str, 
        product_name: str,
        check_interval_hours: int = 24
    ) -> MonitoringResult:
        """ê·œì • ì—…ë°ì´íŠ¸ ëª¨ë‹ˆí„°ë§"""
        
        print(f"ğŸ” ì‹¤ì‹œê°„ ê·œì • ëª¨ë‹ˆí„°ë§ ì‹œì‘ - HSì½”ë“œ: {hs_code}, ìƒí’ˆ: {product_name}")
        
        # ë§ˆì§€ë§‰ ì²´í¬ ì‹œê°„ í™•ì¸
        last_check = self.update_cache.get(hs_code, datetime.now() - timedelta(hours=check_interval_hours))
        
        # ëª¨ë‹ˆí„°ë§ í‚¤ì›Œë“œ ì¶”ì¶œ
        hs_4digit = hs_code.split('.')[0] if '.' in hs_code else hs_code[:4]
        keywords = self.monitoring_keywords.get(hs_4digit, [])
        
        # í‚¤ì›Œë“œì— ìƒí’ˆëª… ì¶”ê°€
        keywords.extend(product_name.lower().split())
        
        updates_found = []
        
        # ê° RSS í”¼ë“œì—ì„œ ì—…ë°ì´íŠ¸ ê²€ìƒ‰
        for agency, feed_url in self.rss_feeds.items():
            try:
                agency_updates = await self._check_feed_for_updates(
                    feed_url, keywords, last_check, agency
                )
                updates_found.extend(agency_updates)
            except Exception as e:
                print(f"âš ï¸ {agency} í”¼ë“œ ì²´í¬ ì‹¤íŒ¨: {e}")
        
        # Federal Register API ì§ì ‘ í˜¸ì¶œ
        try:
            fr_updates = await self._check_federal_register_api(keywords, last_check)
            updates_found.extend(fr_updates)
        except Exception as e:
            print(f"âš ï¸ Federal Register API ì²´í¬ ì‹¤íŒ¨: {e}")
        
        # ì—…ë°ì´íŠ¸ ì •ë ¬ ë° í•„í„°ë§
        updates_found = self._filter_and_sort_updates(updates_found, hs_code)
        
        # ì•Œë¦¼ ë ˆë²¨ ê²°ì •
        alert_level = self._determine_alert_level(updates_found)
        
        # ë‹¤ìŒ ì²´í¬ ì‹œê°„ ê³„ì‚°
        next_check = datetime.now() + timedelta(hours=check_interval_hours)
        
        # ìºì‹œ ì—…ë°ì´íŠ¸
        self.update_cache[hs_code] = datetime.now()
        
        result = MonitoringResult(
            hs_code=hs_code,
            product_name=product_name,
            updates_found=updates_found,
            last_check=datetime.now(),
            next_check_recommended=next_check,
            alert_level=alert_level
        )
        
        print(f"âœ… ëª¨ë‹ˆí„°ë§ ì™„ë£Œ - ì—…ë°ì´íŠ¸ {len(updates_found)}ê°œ ë°œê²¬, ì•Œë¦¼ë ˆë²¨: {alert_level}")
        
        return result
    
    async def _check_feed_for_updates(
        self, 
        feed_url: str, 
        keywords: List[str], 
        last_check: datetime,
        agency: str
    ) -> List[RegulationUpdate]:
        """RSS í”¼ë“œì—ì„œ ì—…ë°ì´íŠ¸ ê²€ìƒ‰"""
        updates = []
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(feed_url, timeout=30) as response:
                    if response.status == 200:
                        content = await response.text()
                        if HAS_FEEDPARSER:
                            feed = feedparser.parse(content)
                        else:
                            print("âš ï¸ feedparser íŒ¨í‚¤ì§€ê°€ ì—†ì–´ RSS í”¼ë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                            feed = None
                        
                        feed_updates = []
                        if feed and hasattr(feed, 'entries'):
                            for entry in feed.entries:
                                # ë°œí–‰ì¼ í™•ì¸ ë‚ ì§œ í™•ì¸
                                pub_date = self._parse_feed_date(entry.get('published', ''))
                                if pub_date and pub_date > last_check:
                                    # í‚¤ì›Œë“œ ë§¤ì¹­ í™•ì¸
                                    title = entry.get('title', '').lower()
                                    summary = entry.get('summary', '').lower()
                                    
                                    if self._contains_keywords(title + ' ' + summary, keywords):
                                        update = RegulationUpdate(
                                            title=entry.get('title', ''),
                                            agency=agency.upper(),
                                            publication_date=pub_date,
                                            effective_date=None,  # RSSì—ì„œëŠ” ë³´í†µ ì œê³µí•˜ì§€ ì•ŠìŒ
                                            summary=entry.get('summary', ''),
                                            url=entry.get('link', ''),
                                            impact_level=self._assess_impact_level(title, summary),
                                            affected_hs_codes=[],  # ë‚˜ì¤‘ì— ë¶„ì„
                                            change_type=self._determine_change_type(title, summary)
                                        )
                                        updates.append(update)
        except Exception as e:
            print(f"RSS í”¼ë“œ íŒŒì‹± ì˜¤ë¥˜ ({feed_url}): {e}")
        
        return updates
    
    async def _check_federal_register_api(
        self, 
        keywords: List[str], 
        last_check: datetime
    ) -> List[RegulationUpdate]:
        """Federal Register APIì—ì„œ ì—…ë°ì´íŠ¸ ê²€ìƒ‰"""
        updates = []
        
        try:
            # ìµœê·¼ 7ì¼ê°„ì˜ ë¬¸ì„œ ê²€ìƒ‰
            start_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
            end_date = datetime.now().strftime('%Y-%m-%d')
            
            # í‚¤ì›Œë“œë³„ë¡œ ê²€ìƒ‰
            for keyword in keywords[:5]:  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš©
                api_url = (
                    f"https://www.federalregister.gov/api/v1/documents.json?"
                    f"per_page=20&"
                    f"publication_date[gte]={start_date}&"
                    f"publication_date[lte]={end_date}&"
                    f"q={keyword}"
                )
                
                async with aiohttp.ClientSession() as session:
                    async with session.get(api_url, timeout=30) as response:
                        if response.status == 200:
                            data = await response.json()
                            
                            for doc in data.get('results', []):
                                pub_date = self._parse_api_date(doc.get('publication_date', ''))
                                if pub_date and pub_date > last_check:
                                    update = RegulationUpdate(
                                        title=doc.get('title', ''),
                                        agency=doc.get('agencies', [{}])[0].get('name', 'FEDERAL_REGISTER'),
                                        publication_date=pub_date,
                                        effective_date=self._parse_api_date(doc.get('effective_on', '')),
                                        summary=doc.get('abstract', ''),
                                        url=doc.get('html_url', ''),
                                        impact_level=self._assess_impact_level(
                                            doc.get('title', ''), 
                                            doc.get('abstract', '')
                                        ),
                                        affected_hs_codes=[],  # ë‚˜ì¤‘ì— ë¶„ì„
                                        change_type=self._determine_change_type(
                                            doc.get('title', ''), 
                                            doc.get('abstract', '')
                                        )
                                    )
                                    updates.append(update)
        except Exception as e:
            print(f"Federal Register API ì˜¤ë¥˜: {e}")
        
        return updates
    
    def _parse_feed_date(self, date_str: str) -> Optional[datetime]:
        """RSS í”¼ë“œ ë‚ ì§œ íŒŒì‹±"""
        try:
            # feedparserê°€ íŒŒì‹±í•œ ì‹œê°„ ì‚¬ìš©
            if hasattr(date_str, 'timetuple'):
                return datetime(*date_str.timetuple()[:6])
            return None
        except:
            return None
    
    def _parse_api_date(self, date_str: str) -> Optional[datetime]:
        """API ë‚ ì§œ íŒŒì‹±"""
        try:
            return datetime.fromisoformat(date_str.replace('Z', '+00:00'))
        except:
            return None
    
    def _contains_keywords(self, text: str, keywords: List[str]) -> bool:
        """í…ìŠ¤íŠ¸ì— í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸"""
        text_lower = text.lower()
        return any(keyword.lower() in text_lower for keyword in keywords)
    
    def _assess_impact_level(self, title: str, summary: str) -> str:
        """ì˜í–¥ ë ˆë²¨ í‰ê°€"""
        text = (title + ' ' + summary).lower()
        
        critical_keywords = ['ban', 'prohibit', 'recall', 'emergency', 'immediate']
        high_keywords = ['restrict', 'limit', 'require', 'mandatory', 'compliance']
        medium_keywords = ['update', 'revise', 'modify', 'clarify', 'guidance']
        
        if any(keyword in text for keyword in critical_keywords):
            return "critical"
        elif any(keyword in text for keyword in high_keywords):
            return "high"
        elif any(keyword in text for keyword in medium_keywords):
            return "medium"
        else:
            return "low"
    
    def _determine_change_type(self, title: str, summary: str) -> str:
        """ë³€ê²½ ìœ í˜• ê²°ì •"""
        text = (title + ' ' + summary).lower()
        
        if 'new' in text or 'establish' in text:
            return "new"
        elif 'amend' in text or 'revise' in text or 'update' in text:
            return "amendment"
        elif 'repeal' in text or 'remove' in text or 'eliminate' in text:
            return "repeal"
        elif 'clarify' in text or 'guidance' in text:
            return "clarification"
        else:
            return "amendment"  # ê¸°ë³¸ê°’
    
    def _filter_and_sort_updates(
        self, 
        updates: List[RegulationUpdate], 
        hs_code: str
    ) -> List[RegulationUpdate]:
        """ì—…ë°ì´íŠ¸ í•„í„°ë§ ë° ì •ë ¬"""
        # ì¤‘ë³µ ì œê±° (URL ê¸°ì¤€)
        seen_urls = set()
        unique_updates = []
        for update in updates:
            if update.url not in seen_urls:
                seen_urls.add(update.url)
                unique_updates.append(update)
        
        # ë°œí–‰ì¼ ê¸°ì¤€ ì •ë ¬ (ìµœì‹ ìˆœ)
        unique_updates.sort(key=lambda x: x.publication_date, reverse=True)
        
        # ìµœëŒ€ 10ê°œë§Œ ë°˜í™˜
        return unique_updates[:10]
    
    def _determine_alert_level(self, updates: List[RegulationUpdate]) -> str:
        """ì•Œë¦¼ ë ˆë²¨ ê²°ì •"""
        if not updates:
            return "none"
        
        # ê°€ì¥ ë†’ì€ ì˜í–¥ ë ˆë²¨ í™•ì¸
        impact_levels = [update.impact_level for update in updates]
        
        if "critical" in impact_levels:
            return "critical"
        elif "high" in impact_levels:
            return "high"
        elif "medium" in impact_levels:
            return "medium"
        else:
            return "low"
    
    def format_monitoring_result(self, result: MonitoringResult) -> Dict[str, Any]:
        """ëª¨ë‹ˆí„°ë§ ê²°ê³¼ë¥¼ API ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        return {
            "live_updates": {
                "hs_code": result.hs_code,
                "product_name": result.product_name,
                "alert_level": result.alert_level,
                "updates_count": len(result.updates_found),
                "updates": [
                    {
                        "title": update.title,
                        "agency": update.agency,
                        "publication_date": update.publication_date.isoformat(),
                        "effective_date": update.effective_date.isoformat() if update.effective_date else None,
                        "summary": update.summary,
                        "url": update.url,
                        "impact_level": update.impact_level,
                        "change_type": update.change_type
                    }
                    for update in result.updates_found
                ],
                "last_check": result.last_check.isoformat(),
                "next_check_recommended": result.next_check_recommended.isoformat(),
                "status": "completed"
            }
        }
