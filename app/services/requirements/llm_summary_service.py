"""
LLM ìš”ì•½ ì„œë¹„ìŠ¤
GPTë¥¼ ì‚¬ìš©í•œ ê·œì • ë¬¸ì„œ ìš”ì•½ ë° êµ¬ì¡°í™”
"""

import asyncio
import json
import hashlib
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import aiohttp
from openai import AsyncOpenAI

@dataclass
class SummaryResult:
    """ìš”ì•½ ê²°ê³¼"""
    hs_code: str
    product_name: str
    critical_requirements: List[str]
    required_documents: List[str]
    compliance_steps: List[str]
    estimated_costs: Dict[str, str]
    timeline: str
    risk_factors: List[str]
    recommendations: List[str]
    model_used: str
    tokens_used: int
    cost: float
    confidence_score: float

class LlmSummaryService:
    """LLM ìš”ì•½ ì„œë¹„ìŠ¤"""
    
    def __init__(self, backend_api_url: str = "http://localhost:8081"):
        self.backend_api_url = backend_api_url
        self.openai_client = AsyncOpenAI()
        self.cache_ttl = 86400  # 24ì‹œê°„
        
        # GPT í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (Citations í¬í•¨)
        self.summary_prompt_template = """
You are an expert US import compliance analyst. Analyze the import regulations for product "{product_name}" (HS Code: {hs_code}) based on the following official sources.

## Available Sources (with URLs):
{documents}

## Your Task:
Provide a comprehensive, actionable analysis in JSON format. **IMPORTANT**: For each requirement, document, or recommendation, include the source URL(s) that support it.

## Response Format (JSON):
{{
    "critical_requirements": [
        {{
            "requirement": "Specific requirement description",
            "agency": "FDA/USDA/EPA/etc",
            "source_url": "https://...",
            "severity": "mandatory/recommended",
            "penalty_if_violated": "Brief description of consequences",
            "effective_date": "YYYY-MM-DD (when this regulation took effect)",
            "last_updated": "YYYY-MM-DD (most recent update)"
        }}
    ],
    "required_documents": [
        {{
            "document": "Document name",
            "issuing_authority": "Who issues this",
            "source_url": "https://...",
            "estimated_time": "Processing time",
            "notes": "Important details"
        }}
    ],
    "compliance_steps": [
        {{
            "step": 1,
            "action": "Specific action to take",
            "responsible_party": "Who should do this",
            "source_url": "https://...",
            "estimated_duration": "Time needed",
            "dependencies": ["Previous steps if any"]
        }}
    ],
    "estimated_costs": {{
        "certification": {{"min": 500, "max": 1000, "currency": "USD", "source_url": "https://..."}},
        "testing": {{"min": 300, "max": 800, "currency": "USD", "source_url": "https://..."}},
        "legal_review": {{"min": 200, "max": 500, "currency": "USD", "source_url": "https://..."}},
        "total": {{"min": 1000, "max": 2300, "currency": "USD"}},
        "notes": "Cost estimates based on typical cases"
    }},
    "timeline": {{
        "minimum_days": 30,
        "typical_days": 45,
        "maximum_days": 60,
        "critical_path": ["Step 1", "Step 2", "Step 3"],
        "source_url": "https://..."
    }},
    "risk_factors": [
        {{
            "risk": "Specific risk description",
            "likelihood": "high/medium/low",
            "impact": "high/medium/low",
            "mitigation": "How to mitigate this risk",
            "source_url": "https://..."
        }}
    ],
    "recommendations": [
        {{
            "recommendation": "Actionable recommendation",
            "priority": "high/medium/low",
            "rationale": "Why this is important",
            "source_url": "https://..."
        }}
    ],
    "labeling_requirements": [
        {{
            "element": "Ingredient list/Country of origin/etc",
            "requirement": "Specific requirement",
            "agency": "FDA/FTC/etc",
            "source_url": "https://...",
            "format": "Required format",
            "placement": "Where on package",
            "language": "English/Bilingual",
            "penalties": "Consequences if non-compliant"
        }}
    ],
    "prohibited_restricted_substances": [
        {{
            "substance": "Chemical name",
            "status": "prohibited/restricted",
            "max_concentration": "If restricted",
            "agency": "Regulating agency",
            "source_url": "https://...",
            "alternatives": ["Safe alternatives if available"]
        }}
    ],
    "prior_notifications": [
        {{
            "type": "FDA Prior Notice/EPA notification/etc",
            "required_for": "Product categories",
            "deadline": "When to submit",
            "submission_method": "How to submit",
            "source_url": "https://...",
            "processing_time": "Expected time",
            "consequences_if_missed": "What happens"
        }}
    ],
    "testing_requirements": [
        {{
            "test": "Test name",
            "required_by": "Agency",
            "frequency": "How often",
            "accredited_labs": ["Lab names"],
            "cost_per_test": {{"min": 200, "max": 500, "currency": "USD"}},
            "turnaround_time": "Days",
            "source_url": "https://...",
            "pass_criteria": "Acceptance criteria"
        }}
    ],
    "third_party_certifications": [
        {{
            "certification": "Certification name",
            "type": "mandatory/voluntary",
            "purpose": "What it certifies",
            "cost_range": {{"min": 1000, "max": 5000, "currency": "USD"}},
            "validity": "Duration",
            "recognized_bodies": ["Certifying organizations"],
            "source_url": "https://...",
            "market_advantage": "Business benefit"
        }}
    ],
    "customs_clearance": {{
        "entry_filing": {{
            "deadline": "15 days after arrival",
            "required_forms": ["Form names"],
            "source_url": "https://..."
        }},
        "bonds_required": {{
            "type": "Single/Continuous",
            "amount": "Dollar amount",
            "source_url": "https://..."
        }},
        "inspection_probability": "high/medium/low with factors"
    }},
    "state_requirements": [
        {{
            "state": "California/New York/etc",
            "requirement": "Specific state requirement",
            "applies_to": "Product categories",
            "source_url": "https://...",
            "penalty": "State-level penalties"
        }}
    ],
    "key_agencies": [
        {{
            "agency": "FDA/USDA/EPA/etc",
            "role": "What they regulate",
            "contact": "Contact information if available",
            "website": "Official website URL"
        }}
    ],
    "regulatory_updates": {{
        "recent_changes": [
            {{
                "date": "YYYY-MM-DD",
                "agency": "Agency name",
                "change": "What changed",
                "impact": "How it affects this product",
                "effective_date": "When it takes effect",
                "source_url": "https://..."
            }}
        ],
        "pending_legislation": "Any upcoming changes to watch"
    }},
    "confidence_score": 0.85,
    "analysis_notes": "Any important caveats or additional context",
    "data_completeness": {{
        "sources_found": 5,
        "sources_expected": 8,
        "missing_areas": ["Areas where data is lacking"],
        "recommendation": "Consult customs broker/attorney if needed"
    }}
}}

## Guidelines:
1. **Citations**: Every claim MUST include a source_url from the provided sources
2. **Specificity**: Use exact numbers, dates, and requirements (not vague terms)
3. **Actionability**: Each step should be clear enough to execute immediately
4. **Prioritization**: Order items by importance/urgency
5. **Risk Assessment**: Be realistic about potential issues
6. **Cost Accuracy**: Provide ranges based on typical cases, cite sources
7. **Timeline Realism**: Account for government processing times
8. **Agency Identification**: Clearly identify which agency regulates what
9. **Confidence**: Lower confidence if sources are limited or contradictory
10. **Product-Specific**: Tailor advice to the specific HS code and product category
11. **Labeling Focus**: Pay special attention to labeling requirements (critical for customs)
12. **Prohibited Substances**: Explicitly identify any banned/restricted ingredients
13. **Prior Notice**: Highlight any pre-arrival notification requirements
14. **Testing**: Specify which tests are mandatory vs recommended
15. **State Laws**: Include California Prop 65 and other major state requirements
16. **Practical Costs**: Include all costs (testing, certification, legal, bonds, insurance)
17. **Customs Reality**: Mention inspection probability and common detention reasons
18. **Market Access**: Note retailer-specific requirements (Amazon, Walmart, etc)
19. **Updates**: Flag recent regulatory changes that may affect compliance
20. **Completeness**: Indicate data gaps and recommend professional consultation when needed
21. **Dates**: Extract effective_date and last_updated from source data when available (FDA uses report_date, recall_initiation_date)
22. **Recency**: Prioritize more recent regulations and flag outdated information

## Important:
- If information is missing from sources, indicate "Not found in provided sources"
- Do not make up URLs - only use URLs from the provided sources
- If multiple sources conflict, note the discrepancy
- Focus on US import requirements only
- Prioritize official government sources over general information

## JSON Formatting Rules (CRITICAL):
- **Escape Special Characters**: All quotes, newlines, and backslashes in strings MUST be properly escaped
- **No Line Breaks in Strings**: Keep all text in single lines within JSON strings (no \\n unless escaped)
- **Short Text**: Keep requirement/recommendation texts under 200 characters each
- **Valid Strings**: Ensure all strings are properly closed with double quotes
- **Test Your JSON**: The output must be valid JSON parseable by standard parsers

Return ONLY valid, parseable JSON. No markdown, no comments, no additional text.
"""
    
    async def summarize_regulations(
        self, 
        hs_code: str, 
        product_name: str,
        raw_documents: List[Dict[str, Any]]
    ) -> SummaryResult:
        """ê·œì • ë¬¸ì„œ ìš”ì•½"""
        
        print(f"ğŸ¤– LLM ìš”ì•½ ì‹œì‘ - HSì½”ë“œ: {hs_code}, ìƒí’ˆ: {product_name}")
        
        # ë¬¸ì„œ í•´ì‹œ ìƒì„± (ìºì‹œ í‚¤ìš©)
        documents_hash = self._generate_documents_hash(raw_documents)
        
        # ìºì‹œ í™•ì¸
        cached_result = await self._get_from_cache(hs_code, product_name, documents_hash)
        if cached_result:
            print(f"âœ… LLM ìºì‹œì—ì„œ ì¡°íšŒ")
            return cached_result
        
        # ë¬¸ì„œ ë‚´ìš© ì¶”ì¶œ ë° ì •ë¦¬
        document_texts = self._extract_document_texts(raw_documents)
        
        if not document_texts:
            print(f"âš ï¸ ìš”ì•½í•  ë¬¸ì„œ ë‚´ìš©ì´ ì—†ìŒ")
            return self._create_empty_summary(hs_code, product_name)
        
        # GPT ìš”ì•½ ì‹¤í–‰
        summary_data = await self._call_gpt_summary(hs_code, product_name, document_texts)
        
        if not summary_data:
            print(f"âŒ GPT ìš”ì•½ ì‹¤íŒ¨")
            return self._create_empty_summary(hs_code, product_name)
        
        # ê²°ê³¼ ê°ì²´ ìƒì„±
        result = SummaryResult(
            hs_code=hs_code,
            product_name=product_name,
            critical_requirements=summary_data.get("critical_requirements", []),
            required_documents=summary_data.get("required_documents", []),
            compliance_steps=summary_data.get("compliance_steps", []),
            estimated_costs=summary_data.get("estimated_costs", {}),
            timeline=summary_data.get("timeline", "ì •ë³´ ì—†ìŒ"),
            risk_factors=summary_data.get("risk_factors", []),
            recommendations=summary_data.get("recommendations", []),
            model_used="gpt-4o-mini",
            tokens_used=summary_data.get("tokens_used", 0),
            cost=summary_data.get("cost", 0.0),
            confidence_score=summary_data.get("confidence_score", 0.0)
        )
        
        # ìºì‹œì— ì €ì¥
        await self._save_to_cache(result, documents_hash)
        
        print(f"âœ… LLM ìš”ì•½ ì™„ë£Œ - ì‹ ë¢°ë„: {result.confidence_score:.2f}")
        return result
    
    def _extract_document_texts(self, raw_documents: List[Dict[str, Any]]) -> List[str]:
        """ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        texts = []
        
        for doc in raw_documents:
            # ë‹¤ì–‘í•œ í•„ë“œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text_fields = ["content", "summary", "description", "text", "body"]
            
            for field in text_fields:
                if field in doc and doc[field]:
                    text = str(doc[field])
                    if len(text) > 50:  # ì˜ë¯¸ìˆëŠ” ê¸¸ì´ì˜ í…ìŠ¤íŠ¸ë§Œ
                        texts.append(text[:2000])  # ìµœëŒ€ 2000ìë¡œ ì œí•œ
                        break
            
            # ì œëª©ë„ í¬í•¨
            if "title" in doc and doc["title"]:
                texts.append(f"ì œëª©: {doc['title']}")
        
        # ì¤‘ë³µ ì œê±° ë° ê¸¸ì´ ì œí•œ
        unique_texts = list(set(texts))
        return unique_texts[:10]  # ìµœëŒ€ 10ê°œ ë¬¸ì„œë§Œ ì²˜ë¦¬
    
    async def _call_gpt_summary(
        self, 
        hs_code: str, 
        product_name: str, 
        document_texts: List[str]
    ) -> Optional[Dict[str, Any]]:
        """GPT ìš”ì•½ í˜¸ì¶œ"""
        try:
            # ë¬¸ì„œ ë‚´ìš© ê²°í•©
            combined_text = "\n\n".join(document_texts)
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.summary_prompt_template.format(
                hs_code=hs_code,
                product_name=product_name,
                documents=combined_text
            )
            
            # í† í° ìˆ˜ ì¶”ì •
            estimated_tokens = len(prompt.split()) * 1.3  # ëŒ€ëµì ì¸ ì¶”ì •
            
            # GPT í˜¸ì¶œ
            start_time = datetime.now()
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                response_format={"type": "json_object"},
                max_tokens=2000
            )
            
            response_time = (datetime.now() - start_time).total_seconds()
            
            # ì‘ë‹µ íŒŒì‹± (JSON íŒŒì‹± ì—ëŸ¬ ë°©ì§€)
            try:
                content = response.choices[0].message.content
                result = json.loads(content)
            except json.JSONDecodeError as json_err:
                print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {json_err}")
                print(f"ğŸ“„ GPT ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 500ì): {content[:500] if content else 'None'}")
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
                return None
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            result["tokens_used"] = response.usage.total_tokens
            result["cost"] = self._calculate_cost(response.usage.total_tokens)
            result["response_time"] = response_time
            
            print(f"âœ… GPT ìš”ì•½ ì™„ë£Œ - í† í°: {result['tokens_used']}, ë¹„ìš©: ${result['cost']:.4f}")
            
            return result
            
        except json.JSONDecodeError as json_err:
            print(f"âŒ GPT ìš”ì•½ ì‹¤íŒ¨ (JSON íŒŒì‹±): {json_err}")
            return None
        except Exception as e:
            print(f"âŒ GPT ìš”ì•½ ì‹¤íŒ¨: {e}")
            return None
    
    def _calculate_cost(self, tokens: int) -> float:
        """í† í° ë¹„ìš© ê³„ì‚° (GPT-4o-mini ê¸°ì¤€)"""
        # GPT-4o-mini ë¹„ìš©: $0.00015/1K input tokens, $0.0006/1K output tokens
        # ëŒ€ëµì ì¸ ê³„ì‚° (ì…ë ¥:ì¶œë ¥ = 3:1 ë¹„ìœ¨ ê°€ì •)
        input_tokens = int(tokens * 0.75)
        output_tokens = int(tokens * 0.25)
        
        input_cost = (input_tokens / 1000) * 0.00015
        output_cost = (output_tokens / 1000) * 0.0006
        
        return input_cost + output_cost
    
    def _generate_documents_hash(self, documents: List[Dict[str, Any]]) -> str:
        """ë¬¸ì„œ í•´ì‹œ ìƒì„±"""
        # ë¬¸ì„œ ë‚´ìš©ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        doc_strings = []
        for doc in documents:
            doc_str = f"{doc.get('title', '')}_{doc.get('content', '')}_{doc.get('summary', '')}"
            doc_strings.append(doc_str)
        
        # í•´ì‹œ ìƒì„±
        combined = "|".join(doc_strings)
        return hashlib.md5(combined.encode()).hexdigest()
    
    async def _get_from_cache(
        self, 
        hs_code: str, 
        product_name: str, 
        documents_hash: str
    ) -> Optional[SummaryResult]:
        """ìºì‹œì—ì„œ ìš”ì•½ ê²°ê³¼ ì¡°íšŒ"""
        try:
            async with aiohttp.ClientSession() as session:
                url = f"{self.backend_api_url}/api/llm-summary-cache/search"
                params = {
                    "hs_code": hs_code,
                    "product_name": product_name,
                    "documents_hash": documents_hash
                }
                
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        if data:
                            return self._parse_cached_result(data)
        except Exception as e:
            print(f"âš ï¸ LLM ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return None
    
    async def _save_to_cache(self, result: SummaryResult, documents_hash: str):
        """ìš”ì•½ ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥"""
        try:
            async with aiohttp.ClientSession() as session:
                url = f"{self.backend_api_url}/api/llm-summary-cache"
                data = {
                    "hsCode": result.hs_code,
                    "productName": result.product_name,
                    "rawDocumentsHash": documents_hash,
                    "summaryResult": json.dumps({
                        "critical_requirements": result.critical_requirements,
                        "required_documents": result.required_documents,
                        "compliance_steps": result.compliance_steps,
                        "estimated_costs": result.estimated_costs,
                        "timeline": result.timeline,
                        "risk_factors": result.risk_factors,
                        "recommendations": result.recommendations,
                        "confidence_score": result.confidence_score
                    }),
                    "modelUsed": result.model_used,
                    "tokensUsed": result.tokens_used,
                    "cost": result.cost,
                    "expiresAt": (datetime.now() + timedelta(seconds=self.cache_ttl)).isoformat()
                }
                
                async with session.post(url, json=data) as response:
                    if response.status in [200, 201]:
                        print(f"âœ… LLM ìºì‹œ ì €ì¥ ì™„ë£Œ")
                    else:
                        print(f"âŒ LLM ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {response.status}")
                        
        except Exception as e:
            print(f"âŒ LLM ìºì‹œ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def _parse_cached_result(self, data: Dict[str, Any]) -> SummaryResult:
        """ìºì‹œëœ ê²°ê³¼ íŒŒì‹±"""
        summary_data = json.loads(data["summaryResult"])
        
        return SummaryResult(
            hs_code=data["hsCode"],
            product_name=data["productName"],
            critical_requirements=summary_data.get("critical_requirements", []),
            required_documents=summary_data.get("required_documents", []),
            compliance_steps=summary_data.get("compliance_steps", []),
            estimated_costs=summary_data.get("estimated_costs", {}),
            timeline=summary_data.get("timeline", "ì •ë³´ ì—†ìŒ"),
            risk_factors=summary_data.get("risk_factors", []),
            recommendations=summary_data.get("recommendations", []),
            model_used=data["modelUsed"],
            tokens_used=data["tokensUsed"],
            cost=float(data["cost"]),
            confidence_score=summary_data.get("confidence_score", 0.0)
        )
    
    def _create_empty_summary(self, hs_code: str, product_name: str) -> SummaryResult:
        """ë¹ˆ ìš”ì•½ ê²°ê³¼ ìƒì„±"""
        return SummaryResult(
            hs_code=hs_code,
            product_name=product_name,
            critical_requirements=["ë¬¸ì„œ ë¶„ì„ ì‹¤íŒ¨ - ìˆ˜ë™ ê²€í†  í•„ìš”"],
            required_documents=["ê¸°ë³¸ ìˆ˜ì… ì„œë¥˜ í™•ì¸ í•„ìš”"],
            compliance_steps=["1ë‹¨ê³„: ê´€ë ¨ ê¸°ê´€ ë¬¸ì˜", "2ë‹¨ê³„: ìš”êµ¬ì‚¬í•­ í™•ì¸"],
            estimated_costs={"total": "ë¹„ìš© ì‚°ì • ë¶ˆê°€"},
            timeline="ì†Œìš” ì‹œê°„ ì‚°ì • ë¶ˆê°€",
            risk_factors=["ìš”êµ¬ì‚¬í•­ ë¶ˆëª…í™•"],
            recommendations=["ì „ë¬¸ê°€ ìƒë‹´ ê¶Œì¥"],
            model_used="none",
            tokens_used=0,
            cost=0.0,
            confidence_score=0.0
        )
    
    async def get_summary_statistics(self) -> Dict[str, Any]:
        """ìš”ì•½ í†µê³„ ì¡°íšŒ"""
        try:
            async with aiohttp.ClientSession() as session:
                url = f"{self.backend_api_url}/api/llm-summary-cache/statistics"
                
                async with session.get(url) as response:
                    if response.status == 200:
                        return await response.json()
                    else:
                        return {"error": f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {response.status}"}
                        
        except Exception as e:
            return {"error": f"í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}"}
    
    def format_summary_result(self, result: SummaryResult) -> Dict[str, Any]:
        """ìš”ì•½ ê²°ê³¼ë¥¼ API ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        return {
            "llm_summary": {
                "hs_code": result.hs_code,
                "product_name": result.product_name,
                "critical_requirements": result.critical_requirements,
                "required_documents": result.required_documents,
                "compliance_steps": result.compliance_steps,
                "estimated_costs": result.estimated_costs,
                "timeline": result.timeline,
                "risk_factors": result.risk_factors,
                "recommendations": result.recommendations,
                "model_used": result.model_used,
                "tokens_used": result.tokens_used,
                "cost": result.cost,
                "confidence_score": result.confidence_score,
                "status": "completed"
            }
        }
