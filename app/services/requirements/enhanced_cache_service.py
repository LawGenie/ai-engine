"""
í–¥ìƒëœ ìºì‹± ì‹œìŠ¤í…œ
ë‹¤ì¸µ ìºì‹±, TTL ê´€ë¦¬, ìºì‹œ ë¬´íš¨í™”, ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë“±ì„ í¬í•¨
"""

import asyncio
import json
import hashlib
import pickle
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from pathlib import Path
import aiofiles
import logging
from collections import OrderedDict
import time

@dataclass
class CacheEntry:
    """ìºì‹œ ì—”íŠ¸ë¦¬"""
    key: str
    value: Any
    created_at: datetime
    expires_at: datetime
    access_count: int = 0
    last_accessed: datetime = None
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.last_accessed is None:
            self.last_accessed = self.created_at
        if self.metadata is None:
            self.metadata = {}

class EnhancedCacheService:
    """í–¥ìƒëœ ìºì‹± ì„œë¹„ìŠ¤"""
    
    def __init__(
        self,
        memory_cache_size: int = 1000,
        disk_cache_dir: str = "cache",
        default_ttl: int = 3600,  # 1ì‹œê°„
        backend_api_url: str = "http://localhost:8081"
    ):
        self.logger = logging.getLogger(__name__)
        
        # ìºì‹œ ì„¤ì •
        self.memory_cache_size = memory_cache_size
        self.disk_cache_dir = Path(disk_cache_dir)
        self.default_ttl = default_ttl
        self.backend_api_url = backend_api_url
        
        # ë‹¤ì¸µ ìºì‹œ
        self.memory_cache: OrderedDict = OrderedDict()
        self.disk_cache_dir.mkdir(exist_ok=True)
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.metrics = {
            'hits': 0,
            'misses': 0,
            'memory_hits': 0,
            'disk_hits': 0,
            'backend_hits': 0,
            'evictions': 0,
            'total_requests': 0
        }
        
        # ìºì‹œ ë¬´íš¨í™” íŒ¨í„´
        self.invalidation_patterns = set()
        
        self.logger.info(f"âœ… í–¥ìƒëœ ìºì‹± ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        self.logger.info(f"   ë©”ëª¨ë¦¬ ìºì‹œ í¬ê¸°: {memory_cache_size}")
        self.logger.info(f"   ë””ìŠ¤í¬ ìºì‹œ ë””ë ‰í† ë¦¬: {disk_cache_dir}")
        self.logger.info(f"   ê¸°ë³¸ TTL: {default_ttl}ì´ˆ")
    
    def _generate_cache_key(self, *args, **kwargs) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_data = {'args': args, 'kwargs': sorted(kwargs.items())}
        key_str = json.dumps(key_data, sort_keys=True, default=str)
        return hashlib.md5(key_str.encode()).hexdigest()
    
    async def get(
        self,
        key: str,
        default: Any = None,
        update_access: bool = True
    ) -> Any:
        """ìºì‹œì—ì„œ ê°’ ì¡°íšŒ"""
        self.metrics['total_requests'] += 1
        
        try:
            # 1. ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
            if key in self.memory_cache:
                entry = self.memory_cache[key]
                if datetime.now() < entry.expires_at:
                    if update_access:
                        entry.access_count += 1
                        entry.last_accessed = datetime.now()
                        # LRU ì—…ë°ì´íŠ¸
                        self.memory_cache.move_to_end(key)
                    self.metrics['hits'] += 1
                    self.metrics['memory_hits'] += 1
                    self.logger.debug(f"âœ… ë©”ëª¨ë¦¬ ìºì‹œ íˆíŠ¸: {key}")
                    return entry.value
                else:
                    # ë§Œë£Œëœ ìºì‹œ ì œê±°
                    del self.memory_cache[key]
                    self.metrics['evictions'] += 1
            
            # 2. ë””ìŠ¤í¬ ìºì‹œ í™•ì¸
            disk_value = await self._get_from_disk(key)
            if disk_value is not None:
                if update_access:
                    # ë©”ëª¨ë¦¬ ìºì‹œì— ë‹¤ì‹œ ë¡œë“œ
                    await self.set(key, disk_value, ttl=self.default_ttl)
                self.metrics['hits'] += 1
                self.metrics['disk_hits'] += 1
                self.logger.debug(f"âœ… ë””ìŠ¤í¬ ìºì‹œ íˆíŠ¸: {key}")
                return disk_value
            
            # 3. ë°±ì—”ë“œ ìºì‹œ í™•ì¸
            backend_value = await self._get_from_backend(key)
            if backend_value is not None:
                if update_access:
                    # ë¡œì»¬ ìºì‹œì— ì €ì¥
                    await self.set(key, backend_value, ttl=self.default_ttl)
                self.metrics['hits'] += 1
                self.metrics['backend_hits'] += 1
                self.logger.debug(f"âœ… ë°±ì—”ë“œ ìºì‹œ íˆíŠ¸: {key}")
                return backend_value
            
            # ìºì‹œ ë¯¸ìŠ¤
            self.metrics['misses'] += 1
            self.logger.debug(f"âŒ ìºì‹œ ë¯¸ìŠ¤: {key}")
            return default
            
        except Exception as e:
            self.logger.error(f"âŒ ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {key}, ì—ëŸ¬: {e}")
            self.metrics['misses'] += 1
            return default
    
    async def set(
        self,
        key: str,
        value: Any,
        ttl: int = None,
        metadata: Dict[str, Any] = None
    ) -> bool:
        """ìºì‹œì— ê°’ ì €ì¥"""
        try:
            ttl = ttl or self.default_ttl
            now = datetime.now()
            
            entry = CacheEntry(
                key=key,
                value=value,
                created_at=now,
                expires_at=now + timedelta(seconds=ttl),
                metadata=metadata or {}
            )
            
            # ë©”ëª¨ë¦¬ ìºì‹œì— ì €ì¥
            await self._set_to_memory(key, entry)
            
            # ë””ìŠ¤í¬ ìºì‹œì— ì €ì¥ (ì¤‘ìš”í•œ ë°ì´í„°ë§Œ)
            if self._should_save_to_disk(entry):
                await self._set_to_disk(key, entry)
            
            self.logger.debug(f"âœ… ìºì‹œ ì €ì¥ ì™„ë£Œ: {key}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {key}, ì—ëŸ¬: {e}")
            return False
    
    async def delete(self, key: str) -> bool:
        """ìºì‹œì—ì„œ ê°’ ì‚­ì œ"""
        try:
            # ë©”ëª¨ë¦¬ ìºì‹œì—ì„œ ì‚­ì œ
            if key in self.memory_cache:
                del self.memory_cache[key]
            
            # ë””ìŠ¤í¬ ìºì‹œì—ì„œ ì‚­ì œ
            await self._delete_from_disk(key)
            
            # ë°±ì—”ë“œ ìºì‹œì—ì„œ ì‚­ì œ
            await self._delete_from_backend(key)
            
            self.logger.debug(f"âœ… ìºì‹œ ì‚­ì œ ì™„ë£Œ: {key}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ìºì‹œ ì‚­ì œ ì‹¤íŒ¨: {key}, ì—ëŸ¬: {e}")
            return False
    
    async def invalidate_pattern(self, pattern: str) -> int:
        """íŒ¨í„´ì— ë§ëŠ” ìºì‹œ ë¬´íš¨í™”"""
        invalidated_count = 0
        
        try:
            # ë©”ëª¨ë¦¬ ìºì‹œì—ì„œ íŒ¨í„´ ë§¤ì¹­ ì‚­ì œ
            keys_to_delete = []
            for key in self.memory_cache.keys():
                if pattern in key:
                    keys_to_delete.append(key)
            
            for key in keys_to_delete:
                del self.memory_cache[key]
                invalidated_count += 1
            
            # ë””ìŠ¤í¬ ìºì‹œì—ì„œ íŒ¨í„´ ë§¤ì¹­ ì‚­ì œ
            disk_invalidated = await self._invalidate_disk_pattern(pattern)
            invalidated_count += disk_invalidated
            
            self.logger.info(f"âœ… íŒ¨í„´ ë¬´íš¨í™” ì™„ë£Œ: {pattern}, {invalidated_count}ê°œ ì‚­ì œ")
            return invalidated_count
            
        except Exception as e:
            self.logger.error(f"âŒ íŒ¨í„´ ë¬´íš¨í™” ì‹¤íŒ¨: {pattern}, ì—ëŸ¬: {e}")
            return 0
    
    async def clear(self) -> bool:
        """ëª¨ë“  ìºì‹œ í´ë¦¬ì–´"""
        try:
            # ë©”ëª¨ë¦¬ ìºì‹œ í´ë¦¬ì–´
            self.memory_cache.clear()
            
            # ë””ìŠ¤í¬ ìºì‹œ í´ë¦¬ì–´
            for cache_file in self.disk_cache_dir.glob("*.cache"):
                cache_file.unlink()
            
            # ë°±ì—”ë“œ ìºì‹œ í´ë¦¬ì–´
            await self._clear_backend_cache()
            
            self.logger.info("âœ… ëª¨ë“  ìºì‹œ í´ë¦¬ì–´ ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ìºì‹œ í´ë¦¬ì–´ ì‹¤íŒ¨: {e}")
            return False
    
    async def cleanup_expired(self) -> int:
        """ë§Œë£Œëœ ìºì‹œ ì •ë¦¬"""
        cleaned_count = 0
        now = datetime.now()
        
        try:
            # ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬
            keys_to_delete = []
            for key, entry in self.memory_cache.items():
                if now >= entry.expires_at:
                    keys_to_delete.append(key)
            
            for key in keys_to_delete:
                del self.memory_cache[key]
                cleaned_count += 1
            
            # ë””ìŠ¤í¬ ìºì‹œ ì •ë¦¬
            disk_cleaned = await self._cleanup_disk_expired()
            cleaned_count += disk_cleaned
            
            self.logger.info(f"âœ… ë§Œë£Œëœ ìºì‹œ ì •ë¦¬ ì™„ë£Œ: {cleaned_count}ê°œ")
            return cleaned_count
            
        except Exception as e:
            self.logger.error(f"âŒ ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return 0
    
    def get_metrics(self) -> Dict[str, Any]:
        """ìºì‹œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°˜í™˜"""
        total_requests = self.metrics['total_requests']
        hit_rate = (self.metrics['hits'] / total_requests * 100) if total_requests > 0 else 0
        
        return {
            'hit_rate': round(hit_rate, 2),
            'total_requests': total_requests,
            'hits': self.metrics['hits'],
            'misses': self.metrics['misses'],
            'memory_hits': self.metrics['memory_hits'],
            'disk_hits': self.metrics['disk_hits'],
            'backend_hits': self.metrics['backend_hits'],
            'evictions': self.metrics['evictions'],
            'memory_cache_size': len(self.memory_cache),
            'memory_cache_limit': self.memory_cache_size,
            'disk_cache_files': len(list(self.disk_cache_dir.glob("*.cache"))),
            'timestamp': datetime.now().isoformat()
        }
    
    # ë‚´ë¶€ ë©”ì„œë“œë“¤
    
    async def _set_to_memory(self, key: str, entry: CacheEntry):
        """ë©”ëª¨ë¦¬ ìºì‹œì— ì €ì¥"""
        # LRU ìºì‹œ í¬ê¸° ê´€ë¦¬
        while len(self.memory_cache) >= self.memory_cache_size:
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
            oldest_key, oldest_entry = self.memory_cache.popitem(last=False)
            self.metrics['evictions'] += 1
            self.logger.debug(f"ğŸ—‘ï¸ ë©”ëª¨ë¦¬ ìºì‹œ eviction: {oldest_key}")
        
        self.memory_cache[key] = entry
    
    async def _get_from_disk(self, key: str) -> Any:
        """ë””ìŠ¤í¬ ìºì‹œì—ì„œ ì¡°íšŒ"""
        try:
            cache_file = self.disk_cache_dir / f"{key}.cache"
            if not cache_file.exists():
                return None
            
            async with aiofiles.open(cache_file, 'rb') as f:
                data = await f.read()
                entry = pickle.loads(data)
                
                # ë§Œë£Œ í™•ì¸
                if datetime.now() >= entry.expires_at:
                    cache_file.unlink()
                    return None
                
                return entry.value
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë””ìŠ¤í¬ ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {key}, ì—ëŸ¬: {e}")
            return None
    
    async def _set_to_disk(self, key: str, entry: CacheEntry):
        """ë””ìŠ¤í¬ ìºì‹œì— ì €ì¥"""
        try:
            cache_file = self.disk_cache_dir / f"{key}.cache"
            async with aiofiles.open(cache_file, 'wb') as f:
                data = pickle.dumps(entry)
                await f.write(data)
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë””ìŠ¤í¬ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {key}, ì—ëŸ¬: {e}")
    
    async def _delete_from_disk(self, key: str):
        """ë””ìŠ¤í¬ ìºì‹œì—ì„œ ì‚­ì œ"""
        try:
            cache_file = self.disk_cache_dir / f"{key}.cache"
            if cache_file.exists():
                cache_file.unlink()
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë””ìŠ¤í¬ ìºì‹œ ì‚­ì œ ì‹¤íŒ¨: {key}, ì—ëŸ¬: {e}")
    
    async def _get_from_backend(self, key: str) -> Any:
        """ë°±ì—”ë“œ ìºì‹œì—ì„œ ì¡°íšŒ"""
        try:
            import aiohttp
            async with aiohttp.ClientSession() as session:
                url = f"{self.backend_api_url}/api/cache/{key}"
                async with session.get(url) as response:
                    if response.status == 200:
                        data = await response.json()
                        return data.get('value')
                    return None
        except Exception as e:
            self.logger.debug(f"âš ï¸ ë°±ì—”ë“œ ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {key}, ì—ëŸ¬: {e}")
            return None
    
    async def _delete_from_backend(self, key: str):
        """ë°±ì—”ë“œ ìºì‹œì—ì„œ ì‚­ì œ"""
        try:
            import aiohttp
            async with aiohttp.ClientSession() as session:
                url = f"{self.backend_api_url}/api/cache/{key}"
                async with session.delete(url) as response:
                    return response.status == 200
        except Exception as e:
            self.logger.debug(f"âš ï¸ ë°±ì—”ë“œ ìºì‹œ ì‚­ì œ ì‹¤íŒ¨: {key}, ì—ëŸ¬: {e}")
            return False
    
    async def _clear_backend_cache(self):
        """ë°±ì—”ë“œ ìºì‹œ í´ë¦¬ì–´"""
        try:
            import aiohttp
            async with aiohttp.ClientSession() as session:
                url = f"{self.backend_api_url}/api/cache/clear"
                async with session.delete(url) as response:
                    return response.status == 200
        except Exception as e:
            self.logger.debug(f"âš ï¸ ë°±ì—”ë“œ ìºì‹œ í´ë¦¬ì–´ ì‹¤íŒ¨: {e}")
            return False
    
    def _should_save_to_disk(self, entry: CacheEntry) -> bool:
        """ë””ìŠ¤í¬ì— ì €ì¥í• ì§€ íŒë‹¨"""
        # ë©”íƒ€ë°ì´í„°ì— disk_save í”Œë˜ê·¸ê°€ ìˆìœ¼ë©´ ì €ì¥
        if entry.metadata.get('disk_save', False):
            return True
        
        # í° ë°ì´í„°ëŠ” ë””ìŠ¤í¬ì— ì €ì¥
        try:
            size = len(pickle.dumps(entry.value))
            return size > 1024 * 1024  # 1MB ì´ìƒ
        except:
            return False
    
    async def _invalidate_disk_pattern(self, pattern: str) -> int:
        """ë””ìŠ¤í¬ ìºì‹œì—ì„œ íŒ¨í„´ ë¬´íš¨í™”"""
        invalidated_count = 0
        try:
            for cache_file in self.disk_cache_dir.glob("*.cache"):
                if pattern in cache_file.stem:
                    cache_file.unlink()
                    invalidated_count += 1
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë””ìŠ¤í¬ íŒ¨í„´ ë¬´íš¨í™” ì‹¤íŒ¨: {pattern}, ì—ëŸ¬: {e}")
        return invalidated_count
    
    async def _cleanup_disk_expired(self) -> int:
        """ë””ìŠ¤í¬ ìºì‹œì—ì„œ ë§Œë£Œëœ í•­ëª© ì •ë¦¬"""
        cleaned_count = 0
        now = datetime.now()
        
        try:
            for cache_file in self.disk_cache_dir.glob("*.cache"):
                try:
                    async with aiofiles.open(cache_file, 'rb') as f:
                        data = await f.read()
                        entry = pickle.loads(data)
                        
                        if now >= entry.expires_at:
                            cache_file.unlink()
                            cleaned_count += 1
                except Exception:
                    # ì†ìƒëœ íŒŒì¼ ì‚­ì œ
                    cache_file.unlink()
                    cleaned_count += 1
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë””ìŠ¤í¬ ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
        
        return cleaned_count

# ì „ì—­ ìºì‹œ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
enhanced_cache = EnhancedCacheService()
