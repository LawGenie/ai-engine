"""
LangGraph Workflow for Requirements Analysis
ìš”êµ¬ì‚¬í•­ ë¶„ì„ì„ ìœ„í•œ ì›Œí¬í”Œë¡œìš° ì •ì˜
"""

from typing import Dict, Any, List
from langgraph.graph import StateGraph, END
from .nodes import RequirementsNodes
from .tools import RequirementsTools
from app.models.requirement_models import RequirementAnalysisRequest, RequirementAnalysisResponse, Requirements, Certification, Document, Labeling, Source, Metadata


class RequirementsWorkflow:
    """ìš”êµ¬ì‚¬í•­ ë¶„ì„ LangGraph ì›Œí¬í”Œë¡œìš°"""
    
    def __init__(self):
        self.nodes = RequirementsNodes()
        self.tools = RequirementsTools()
        self.graph = self._build_graph()
    
    def _build_graph(self) -> StateGraph:
        """LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""
        workflow = StateGraph(dict)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("search_documents", self.nodes.search_agency_documents)
        workflow.add_node("scrape_documents", self.nodes.scrape_documents)
        workflow.add_node("consolidate_results", self.nodes.consolidate_results)
        
        # ì—£ì§€ ì •ì˜
        workflow.add_edge("search_documents", "scrape_documents")
        workflow.add_edge("scrape_documents", "consolidate_results")
        workflow.add_edge("consolidate_results", END)
        
        # ì‹œì‘ì  ì„¤ì •
        workflow.set_entry_point("search_documents")
        
        return workflow.compile()
    
    async def analyze_requirements(self, request: RequirementAnalysisRequest) -> RequirementAnalysisResponse:
        """ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì‹¤í–‰"""
        print(f"\nğŸš€ [WORKFLOW] ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì‹œì‘")
        print(f"  ğŸ“‹ HSì½”ë“œ: {request.hs_code}")
        print(f"  ğŸ“¦ ìƒí’ˆëª…: {request.product_name}")
        print(f"  ğŸŒ ëŒ€ìƒêµ­ê°€: {request.target_country}")
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        initial_state = {
            "request": request,
            "search_results": {},
            "scraped_data": {},
            "consolidated_results": {}
        }
        
        try:
            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            final_state = await self.graph.ainvoke(initial_state)
            
            # ë””ë²„ê¹…ì„ ìœ„í•œ ìƒíƒœ ì¶œë ¥
            print(f"\nğŸ” [DEBUG] ìµœì¢… ìƒíƒœ í‚¤: {list(final_state.keys())}")
            
            # ê²°ê³¼ ë³€í™˜ - ìƒíƒœì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
            consolidated = final_state.get("consolidated_results", {})
            print(f"ğŸ” [DEBUG] consolidated_results í‚¤: {list(consolidated.keys()) if consolidated else 'None'}")
            
            # consolidated_resultsê°€ ì—†ìœ¼ë©´ scraped_dataì—ì„œ ì§ì ‘ êµ¬ì„±
            if not consolidated:
                print(f"ğŸ” [DEBUG] consolidated_results ì—†ìŒ, scraped_dataì—ì„œ êµ¬ì„±")
                scraped_data = final_state.get("scraped_data", {})
                print(f"ğŸ” [DEBUG] scraped_data í‚¤: {list(scraped_data.keys())}")
                
                # scraped_dataì—ì„œ ì§ì ‘ í†µí•©
                all_certifications = []
                all_documents = []
                all_sources = []
                
                for agency, data in scraped_data.items():
                    if "error" not in data:
                        all_certifications.extend(data.get("certifications", []))
                        all_documents.extend(data.get("documents", []))
                        all_sources.extend(data.get("sources", []))
                
                consolidated = {
                    "certifications": all_certifications,
                    "documents": all_documents,
                    "sources": all_sources
                }
                print(f"ğŸ” [DEBUG] ì§ì ‘ êµ¬ì„±ëœ consolidated: {len(all_certifications)}ê°œ ì¸ì¦, {len(all_documents)}ê°œ ì„œë¥˜")
            
            # Pydantic ëª¨ë¸ë¡œ ë³€í™˜
            certifications = []
            for cert_data in consolidated.get("certifications", []):
                try:
                    certifications.append(Certification(**cert_data))
                except Exception as e:
                    print(f"  âŒ Certification ë³€í™˜ ì‹¤íŒ¨: {e}")
            
            documents = []
            for doc_data in consolidated.get("documents", []):
                try:
                    documents.append(Document(**doc_data))
                except Exception as e:
                    print(f"  âŒ Document ë³€í™˜ ì‹¤íŒ¨: {e}")
            
            sources = []
            for source_data in consolidated.get("sources", []):
                try:
                    sources.append(Source(**source_data))
                except Exception as e:
                    print(f"  âŒ Source ë³€í™˜ ì‹¤íŒ¨: {e}")
            
            requirements = Requirements(
                certifications=certifications,
                documents=documents,
                labeling=[]  # ë¼ë²¨ë§ ìš”êµ¬ì‚¬í•­ì€ ë³„ë„ êµ¬í˜„ í•„ìš”
            )
            
            # ì‘ë‹µ ìƒì„±
            response = RequirementAnalysisResponse(
                answer=f"HSì½”ë“œ {request.hs_code}ì— ëŒ€í•œ ë¯¸êµ­ ìˆ˜ì…ìš”ê±´ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                reasoning=self._generate_reasoning(request, requirements),
                requirements=requirements,
                sources=sources,
                metadata=Metadata(
                    from_cache=False,
                    confidence=0.85,
                    response_time_ms=2000
                )
            )
            
            print(f"\nâœ… [WORKFLOW] ë¶„ì„ ì™„ë£Œ")
            print(f"  ğŸ“‹ ì¸ì¦ìš”ê±´: {len(certifications)}ê°œ")
            print(f"  ğŸ“„ í•„ìš”ì„œë¥˜: {len(documents)}ê°œ")
            print(f"  ğŸ“š ì¶œì²˜: {len(sources)}ê°œ")
            
            return response
            
        except Exception as e:
            print(f"\nâŒ [WORKFLOW] ë¶„ì„ ì‹¤íŒ¨: {e}")
            
            # ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±
            return RequirementAnalysisResponse(
                answer=f"ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                reasoning="ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•´ ë¶„ì„ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                requirements=Requirements(),
                sources=[],
                metadata=Metadata(
                    from_cache=False,
                    confidence=0.0,
                    response_time_ms=0
                )
            )
    
    def _generate_reasoning(self, request: RequirementAnalysisRequest, requirements: Requirements) -> str:
        """ë¶„ì„ ê·¼ê±° ìƒì„±"""
        cert_count = len(requirements.certifications)
        doc_count = len(requirements.documents)
        
        reasoning = f"HSì½”ë“œ {request.hs_code} ({request.product_name})ì— ëŒ€í•œ ìš”êµ¬ì‚¬í•­ ë¶„ì„ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. "
        reasoning += f"ì´ {cert_count}ê°œì˜ ì¸ì¦ìš”ê±´ê³¼ {doc_count}ê°œì˜ í•„ìš”ì„œë¥˜ê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤. "
        reasoning += "ê° ê·œì œê¸°ê´€ì˜ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤."
        
        return reasoning
