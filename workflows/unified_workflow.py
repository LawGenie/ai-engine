"""
í†µí•© ì›Œí¬í”Œë¡œìš° (Unified Workflow)

ì´ ì›Œí¬í”Œë¡œìš°ëŠ” LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ìš”êµ¬ì‚¬í•­ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

ì›Œí¬í”Œë¡œìš° ë‹¨ê³„:
1. extract_keywords: ì œí’ˆëª…ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
2. search_documents: ì •ë¶€ ê¸°ê´€ ë¬¸ì„œ ê²€ìƒ‰ (ë¬´ë£Œ API + Tavily)
3. hybrid_api_call: í•˜ì´ë¸Œë¦¬ë“œ API í˜¸ì¶œ (HSì½”ë“œ ë§¤í•‘ + ê²€ìƒ‰)
4. scrape_documents: ë¬¸ì„œ ìŠ¤í¬ë˜í•‘
5. consolidate_results: ê²°ê³¼ í†µí•© (LLM ìš”ì•½ í¬í•¨)
6. finalize_results: ìµœì¢… ê²°ê³¼ í¬ë§·íŒ…

íŠ¹ì§•:
- ë³‘ë ¬ ì²˜ë¦¬ ì§€ì› (API ìƒíƒœì— ë”°ë¼ ìë™ ì „í™˜)
- ë‹¤ì¸µ ìºì‹œ (ë©”ëª¨ë¦¬ + ë””ìŠ¤í¬)
- ì—ëŸ¬ í•¸ë“¤ë§ ë° í´ë°±
- ì‹ ë¢°ë„ ê³„ì‚° (ê°€ì¤‘ì¹˜ ê¸°ë°˜ + 5ë‹¨ê³„ ë“±ê¸‰)

ì‚¬ìš© ì˜ˆ:
    workflow = UnifiedRequirementsWorkflow()
    result = await workflow.analyze_requirements(
        hs_code="3304.99",
        product_name="vitamin c serum"
    )
"""

from langgraph.graph import StateGraph
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
from datetime import datetime
import asyncio
from .nodes import RequirementsNodes
from .tools import RequirementsTools
from app.services.requirements.error_handler import error_handler, WorkflowError, ErrorSeverity
from app.services.requirements.env_manager import env_manager
from app.services.requirements.parallel_processor import parallel_processor, ProcessingTask, ProcessingMode
from app.services.requirements.enhanced_cache_service import enhanced_cache
from app.services.requirements.confidence_calculator import get_confidence_calculator

@dataclass
class UnifiedWorkflowState:
    """í†µí•© ì›Œí¬í”Œë¡œìš° ìƒíƒœ"""
    # ì…ë ¥ ë°ì´í„°
    hs_code: str
    product_name: str
    product_description: str = ""
    
    # ì¤‘ê°„ ê²°ê³¼
    core_keywords: List[str] = None
    keyword_strategies: List[Dict[str, Any]] = None
    search_results: Dict[str, Any] = None
    hybrid_result: Dict[str, Any] = None
    scraped_data: Dict[str, Any] = None
    consolidated_results: Dict[str, Any] = None
    
    # ë©”íƒ€ë°ì´í„°
    detailed_metadata: Dict[str, Any] = None
    processing_time_ms: int = 0
    status: str = "pending"
    errors: List[Dict[str, Any]] = None
    
    # ìµœì¢… ê²°ê³¼
    final_result: Dict[str, Any] = None

class UnifiedRequirementsWorkflow:
    """í†µí•© ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì›Œí¬í”Œë¡œìš°"""
    
    def __init__(self):
        self.nodes = RequirementsNodes()
        self.tools = RequirementsTools()
        self.workflow = self._create_workflow()
        
        # API ìƒíƒœ í™•ì¸
        api_status = env_manager.get_api_status_summary()
        print(f"ğŸš€ í†µí•© ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸ“Š API ìƒíƒœ: {api_status['available_api_keys']}/{api_status['total_api_keys']}ê°œ í‚¤ ì‚¬ìš© ê°€ëŠ¥")
    
    def _create_workflow(self) -> StateGraph:
        """ì›Œí¬í”Œë¡œìš° ìƒì„±"""
        workflow = StateGraph(UnifiedWorkflowState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("extract_keywords", self._extract_keywords_node)
        workflow.add_node("search_documents", self._search_documents_node)
        workflow.add_node("hybrid_api_call", self._hybrid_api_call_node)
        workflow.add_node("scrape_documents", self._scrape_documents_node)
        workflow.add_node("consolidate_results", self._consolidate_results_node)
        workflow.add_node("finalize_results", self._finalize_results_node)
        
        # ì—£ì§€ ì¶”ê°€ (ìˆœì°¨ ì‹¤í–‰)
        workflow.add_edge("extract_keywords", "search_documents")
        workflow.add_edge("search_documents", "hybrid_api_call")
        workflow.add_edge("hybrid_api_call", "scrape_documents")
        workflow.add_edge("scrape_documents", "consolidate_results")
        workflow.add_edge("consolidate_results", "finalize_results")
        
        # ì‹œì‘ì ê³¼ ëì  ì„¤ì •
        workflow.set_entry_point("extract_keywords")
        workflow.set_finish_point("finalize_results")
        
        return workflow.compile()
    
    async def _extract_keywords_node(self, state: UnifiedWorkflowState) -> UnifiedWorkflowState:
        """í‚¤ì›Œë“œ ì¶”ì¶œ ë…¸ë“œ"""
        try:
            print(f"\nğŸ” [UNIFIED] í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œì‘")
            
            # RequirementsNodesì˜ extract_core_keywords ë©”ì„œë“œ í˜¸ì¶œ
            temp_state = {"request": type('Request', (), {
                'hs_code': state.hs_code,
                'product_name': state.product_name,
                'product_description': state.product_description
            })()}
            
            result_state = await self.nodes.extract_core_keywords(temp_state)
            
            # ê²°ê³¼ë¥¼ UnifiedWorkflowStateì— ë³µì‚¬
            state.core_keywords = result_state.get("core_keywords", [])
            state.keyword_strategies = result_state.get("keyword_strategies", [])
            state.detailed_metadata = result_state.get("detailed_metadata", {})
            
            print(f"âœ… í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ: {state.core_keywords}")
            
        except Exception as e:
            print(f"âŒ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            error_handler.handle_error(
                WorkflowError(
                    f"í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}",
                    ErrorSeverity.MEDIUM
                ),
                {'step': 'extract_keywords', 'state': state}
            )
            # í´ë°± í‚¤ì›Œë“œ ì‚¬ìš©
            state.core_keywords = ['product', 'import', 'requirement']
            state.keyword_strategies = [{"strategy": "fallback", "keywords": state.core_keywords}]
        
        return state
    
    async def _search_documents_node(self, state: UnifiedWorkflowState) -> UnifiedWorkflowState:
        """ë¬¸ì„œ ê²€ìƒ‰ ë…¸ë“œ"""
        try:
            print(f"\nğŸ” [UNIFIED] ë¬¸ì„œ ê²€ìƒ‰ ì‹œì‘")
            
            # RequirementsNodesì˜ search_agency_documents ë©”ì„œë“œ í˜¸ì¶œ
            temp_state = {
                "request": type('Request', (), {
                    'hs_code': state.hs_code,
                    'product_name': state.product_name,
                    'product_description': state.product_description
                })(),
                "core_keywords": state.core_keywords,
                "keyword_strategies": state.keyword_strategies,
                "detailed_metadata": state.detailed_metadata or {}
            }
            
            result_state = await self.nodes.search_agency_documents(temp_state)
            
            # ê²°ê³¼ ë³µì‚¬
            state.search_results = result_state.get("search_results", {})
            state.detailed_metadata = result_state.get("detailed_metadata", {})
            
            print(f"âœ… ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ: {len(state.search_results)}ê°œ ê¸°ê´€ ê²°ê³¼")
            
        except Exception as e:
            print(f"âŒ ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            error_handler.handle_error(
                WorkflowError(
                    f"ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}",
                    ErrorSeverity.MEDIUM
                ),
                {'step': 'search_documents', 'state': state}
            )
            # ë¹ˆ ê²€ìƒ‰ ê²°ê³¼ë¡œ ê³„ì† ì§„í–‰
            state.search_results = {}
        
        return state
    
    async def _hybrid_api_call_node(self, state: UnifiedWorkflowState) -> UnifiedWorkflowState:
        """í•˜ì´ë¸Œë¦¬ë“œ API í˜¸ì¶œ ë…¸ë“œ"""
        try:
            print(f"\nğŸ“¡ [UNIFIED] í•˜ì´ë¸Œë¦¬ë“œ API í˜¸ì¶œ ì‹œì‘")
            
            # RequirementsNodesì˜ call_hybrid_api ë©”ì„œë“œ í˜¸ì¶œ
            temp_state = {
                "request": type('Request', (), {
                    'hs_code': state.hs_code,
                    'product_name': state.product_name,
                    'product_description': state.product_description
                })(),
                "core_keywords": state.core_keywords,
                "keyword_strategies": state.keyword_strategies,
                "search_results": state.search_results,
                "detailed_metadata": state.detailed_metadata or {}
            }
            
            result_state = await self.nodes.call_hybrid_api(temp_state)
            
            # ê²°ê³¼ ë³µì‚¬
            state.hybrid_result = result_state.get("hybrid_result", {})
            state.detailed_metadata = result_state.get("detailed_metadata", {})
            
            print(f"âœ… í•˜ì´ë¸Œë¦¬ë“œ API í˜¸ì¶œ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            error_handler.handle_error(
                WorkflowError(
                    f"í•˜ì´ë¸Œë¦¬ë“œ API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}",
                    ErrorSeverity.LOW
                ),
                {'step': 'hybrid_api_call', 'state': state}
            )
            # ë¹ˆ ê²°ê³¼ë¡œ ê³„ì† ì§„í–‰
            state.hybrid_result = {}
        
        return state
    
    async def _scrape_documents_node(self, state: UnifiedWorkflowState) -> UnifiedWorkflowState:
        """ë¬¸ì„œ ìŠ¤í¬ë˜í•‘ ë…¸ë“œ"""
        try:
            print(f"\nğŸ” [UNIFIED] ë¬¸ì„œ ìŠ¤í¬ë˜í•‘ ì‹œì‘")
            
            # RequirementsNodesì˜ scrape_documents ë©”ì„œë“œ í˜¸ì¶œ
            temp_state = {
                "request": type('Request', (), {
                    'hs_code': state.hs_code,
                    'product_name': state.product_name,
                    'product_description': state.product_description
                })(),
                "search_results": state.search_results,
                "detailed_metadata": state.detailed_metadata or {}
            }
            
            result_state = await self.nodes.scrape_documents(temp_state)
            
            # ê²°ê³¼ ë³µì‚¬
            state.scraped_data = result_state.get("scraped_data", {})
            state.detailed_metadata = result_state.get("detailed_metadata", {})
            
            print(f"âœ… ë¬¸ì„œ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {len(state.scraped_data)}ê°œ ê¸°ê´€ ì²˜ë¦¬")
            
        except Exception as e:
            print(f"âŒ ë¬¸ì„œ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
            error_handler.handle_error(
                WorkflowError(
                    f"ë¬¸ì„œ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {str(e)}",
                    ErrorSeverity.MEDIUM
                ),
                {'step': 'scrape_documents', 'state': state}
            )
            # ë¹ˆ ìŠ¤í¬ë˜í•‘ ê²°ê³¼ë¡œ ê³„ì† ì§„í–‰
            state.scraped_data = {}
        
        return state
    
    async def _consolidate_results_node(self, state: UnifiedWorkflowState) -> UnifiedWorkflowState:
        """ê²°ê³¼ í†µí•© ë…¸ë“œ"""
        try:
            print(f"\nğŸ” [UNIFIED] ê²°ê³¼ í†µí•© ì‹œì‘")
            
            # RequirementsNodesì˜ consolidate_results ë©”ì„œë“œ í˜¸ì¶œ
            temp_state = {
                "request": type('Request', (), {
                    'hs_code': state.hs_code,
                    'product_name': state.product_name,
                    'product_description': state.product_description
                })(),
                "search_results": state.search_results,
                "hybrid_result": state.hybrid_result,
                "scraped_data": state.scraped_data,
                "detailed_metadata": state.detailed_metadata or {}
            }
            
            result_state = await self.nodes.consolidate_results(temp_state)
            
            # ê²°ê³¼ ë³µì‚¬
            state.consolidated_results = result_state.get("consolidated_results", {})
            state.detailed_metadata = result_state.get("detailed_metadata", {})
            
            print(f"âœ… ê²°ê³¼ í†µí•© ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ê²°ê³¼ í†µí•© ì‹¤íŒ¨: {e}")
            error_handler.handle_error(
                WorkflowError(
                    f"ê²°ê³¼ í†µí•© ì‹¤íŒ¨: {str(e)}",
                    ErrorSeverity.HIGH
                ),
                {'step': 'consolidate_results', 'state': state}
            )
            # ê¸°ë³¸ í†µí•© ê²°ê³¼ ìƒì„±
            state.consolidated_results = {
                "certifications": [],
                "documents": [],
                "sources": [],
                "precedents": []
            }
        
        return state
    
    async def _finalize_results_node(self, state: UnifiedWorkflowState) -> UnifiedWorkflowState:
        """ìµœì¢… ê²°ê³¼ ì •ë¦¬ ë…¸ë“œ"""
        try:
            print(f"\nğŸ¯ [UNIFIED] ìµœì¢… ê²°ê³¼ ì •ë¦¬ ì‹œì‘")
            
            # ìµœì¢… ê²°ê³¼ êµ¬ì„±
            state.final_result = {
                "hs_code": state.hs_code,
                "product_name": state.product_name,
                "product_description": state.product_description,
                "processing_time_ms": state.processing_time_ms,
                "timestamp": datetime.now().isoformat(),
                "status": "completed",
                
                # ë¶„ì„ ê²°ê³¼
                "core_keywords": state.core_keywords,
                
                # Citations (ì¶œì²˜ ì •ë³´)
                "citations": state.consolidated_results.get("citations", []) if state.consolidated_results else [],
                
                # ì‹ ë¢°ë„ ê³„ì‚° (ê°€ì¤‘ì¹˜ ê¸°ë°˜ + 5ë‹¨ê³„ ë“±ê¸‰)
                "confidence_analysis": self._calculate_confidence_analysis(state),
                
                "search_results_summary": {
                    "total_agencies": len(state.search_results) if state.search_results else 0,
                    "agencies_processed": list(state.search_results.keys()) if state.search_results else []
                },
                "hybrid_api_summary": {
                    "success": not state.hybrid_result.get("error") if state.hybrid_result else False,
                    "error": state.hybrid_result.get("error") if state.hybrid_result else None
                },
                "scraping_summary": {
                    "total_agencies_scraped": len(state.scraped_data) if state.scraped_data else 0,
                    "successful_scraping": len([d for d in state.scraped_data.values() 
                                               if d.get("status") == "success"]) if state.scraped_data else 0
                },
                "consolidated_results": state.consolidated_results,
                
                # LLM ìš”ì•½ (ê°€ì¥ ì¤‘ìš”!)
                "llm_summary": state.consolidated_results.get("llm_summary") if state.consolidated_results else None,
                
                # ë©”íƒ€ë°ì´í„°
                "detailed_metadata": state.detailed_metadata,
                "api_status": env_manager.get_api_status_summary(),
                "error_summary": error_handler.get_error_summary()
            }
            
            state.status = "completed"
            print(f"âœ… ìµœì¢… ê²°ê³¼ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ìµœì¢… ê²°ê³¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            error_handler.handle_error(
                WorkflowError(
                    f"ìµœì¢… ê²°ê³¼ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}",
                    ErrorSeverity.HIGH
                ),
                {'step': 'finalize_results', 'state': state}
            )
            state.status = "failed"
            state.final_result = {
                "error": str(e),
                "status": "failed",
                "timestamp": datetime.now().isoformat()
            }
        
        return state
    
    def _calculate_confidence_analysis(self, state: UnifiedWorkflowState) -> Dict[str, Any]:
        """ì‹ ë¢°ë„ ë¶„ì„ ê³„ì‚°"""
        try:
            calculator = get_confidence_calculator()
            
            # ë°ì´í„° ì¶”ì¶œ
            consolidated = state.consolidated_results or {}
            citations = consolidated.get("citations", [])
            
            # ìš”ê±´ ë°ì´í„° (ëª¨ë“  í•­ëª©)
            requirements = []
            if consolidated.get("certifications"):
                requirements.extend(consolidated["certifications"])
            if consolidated.get("documents"):
                requirements.extend(consolidated["documents"])
            if consolidated.get("sources"):
                requirements.extend(consolidated["sources"])
            
            # íƒ€ê²Ÿ ê¸°ê´€ (hybrid_resultì—ì„œ ì¶”ì¶œ)
            target_agencies = []
            target_agencies_data = None
            hs_mapping_confidence = 0.5  # ê¸°ë³¸ê°’
            
            if state.hybrid_result:
                target_agencies_data = state.hybrid_result.get("combined_results", {}).get("target_agencies", {})
                if target_agencies_data:
                    target_agencies = target_agencies_data.get("primary_agencies", [])
                    hs_mapping_confidence = target_agencies_data.get("confidence", 0.5)
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence_result = calculator.calculate_confidence(
                sources=citations,
                requirements=requirements,
                target_agencies=target_agencies,
                hs_code_mapping_confidence=hs_mapping_confidence
            )
            
            print(f"  ğŸ“Š ì‹ ë¢°ë„ ë¶„ì„: {confidence_result['score']:.2f} ({confidence_result['level']})")
            
            return confidence_result
            
        except Exception as e:
            print(f"âš ï¸ ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {
                "score": 0.5,
                "level": "ì¤‘",
                "level_enum": "MEDIUM",
                "breakdown": {},
                "factors": [],
                "warnings": ["ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨"]
            }
    
    async def analyze_requirements(
        self, 
        hs_code: str, 
        product_name: str, 
        product_description: str = "",
        force_refresh: bool = False,
        is_new_product: bool = False
    ) -> Dict[str, Any]:
        """ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì‹¤í–‰ (í†µí•© ì›Œí¬í”Œë¡œìš° + ë³‘ë ¬ ì²˜ë¦¬)"""
        
        print(f"ğŸš€ í†µí•© ì›Œí¬í”Œë¡œìš° ì‹œì‘ - HSì½”ë“œ: {hs_code}, ìƒí’ˆ: {product_name}")
        start_time = datetime.now()
        
        try:
            # ìºì‹œ í™•ì¸
            if not force_refresh and not is_new_product:
                cache_key = enhanced_cache._generate_cache_key(
                    "requirements_analysis", hs_code, product_name
                )
                cached_result = await enhanced_cache.get(cache_key)
                if cached_result:
                    print(f"âœ… ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜")
                    return cached_result
            
            # ì´ˆê¸° ìƒíƒœ ì„¤ì •
            initial_state = UnifiedWorkflowState(
                hs_code=hs_code,
                product_name=product_name,
                product_description=product_description,
                detailed_metadata={},
                errors=[]
            )
            
            # ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥í•œ ë…¸ë“œë“¤ì„ ì‹ë³„í•˜ê³  ë³‘ë ¬ ì‹¤í–‰
            if self._can_parallelize():
                result_state = await self._execute_parallel_workflow(initial_state)
            else:
                # ìˆœì°¨ ì‹¤í–‰
                result_state = await self.workflow.ainvoke(initial_state)
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = int((datetime.now() - start_time).total_seconds() * 1000)
            result_state.processing_time_ms = processing_time
            
            # ìºì‹œì— ì €ì¥
            if result_state.final_result and result_state.status == "completed":
                cache_key = enhanced_cache._generate_cache_key(
                    "requirements_analysis", hs_code, product_name
                )
                await enhanced_cache.set(
                    cache_key, 
                    result_state.final_result, 
                    ttl=3600,  # 1ì‹œê°„
                    metadata={'disk_save': True}
                )
            
            print(f"âœ… í†µí•© ì›Œí¬í”Œë¡œìš° ì™„ë£Œ - ì†Œìš”ì‹œê°„: {processing_time}ms")
            
            return result_state.final_result or {
                "error": "ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨",
                "status": "failed",
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"âŒ í†µí•© ì›Œí¬í”Œë¡œìš° ì‹¤íŒ¨: {e}")
            error_handler.handle_error(
                WorkflowError(
                    f"í†µí•© ì›Œí¬í”Œë¡œìš° ì‹¤íŒ¨: {str(e)}",
                    ErrorSeverity.CRITICAL
                ),
                {'hs_code': hs_code, 'product_name': product_name}
            )
            
            return {
                "error": str(e),
                "status": "failed",
                "timestamp": datetime.now().isoformat(),
                "processing_time_ms": int((datetime.now() - start_time).total_seconds() * 1000)
            }
    
    def _can_parallelize(self) -> bool:
        """ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        # API ìƒíƒœì™€ ë¦¬ì†ŒìŠ¤ ìƒíƒœë¥¼ í™•ì¸í•˜ì—¬ ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨
        api_status = env_manager.get_api_status_summary()
        return api_status['available_api_keys'] > 0
    
    async def _execute_parallel_workflow(self, state: UnifiedWorkflowState) -> UnifiedWorkflowState:
        """ë³‘ë ¬ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        print(f"ğŸ”„ ë³‘ë ¬ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹œì‘")
        
        try:
            # ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥í•œ ì‘ì—…ë“¤ ì •ì˜
            tasks = [
                ProcessingTask(
                    id="extract_keywords",
                    func=self._extract_keywords_node,
                    args=(state,),
                    priority=1
                ),
                ProcessingTask(
                    id="search_documents",
                    func=self._search_documents_node,
                    args=(state,),
                    priority=2
                ),
                ProcessingTask(
                    id="hybrid_api_call",
                    func=self._hybrid_api_call_node,
                    args=(state,),
                    priority=3
                )
            ]
            
            # ë³‘ë ¬ ì‹¤í–‰
            results = await parallel_processor.process_parallel(
                tasks, 
                mode=ProcessingMode.PARALLEL,
                timeout=600.0  # ë°±ì—”ë“œ API íƒ€ì„ì•„ì›ƒ 10ë¶„
            )
            
            # ê²°ê³¼ í†µí•©
            for result in results:
                if result.success:
                    # ìƒíƒœ ì—…ë°ì´íŠ¸ëŠ” ê° ë…¸ë“œì—ì„œ ìˆ˜í–‰ë¨
                    pass
                else:
                    print(f"âš ï¸ ë³‘ë ¬ ì‘ì—… ì‹¤íŒ¨: {result.task_id}, ì—ëŸ¬: {result.error}")
            
            # ìˆœì°¨ ì²˜ë¦¬í•´ì•¼ í•˜ëŠ” ë‚˜ë¨¸ì§€ ë…¸ë“œë“¤ ì‹¤í–‰
            state = await self._scrape_documents_node(state)
            state = await self._consolidate_results_node(state)
            state = await self._finalize_results_node(state)
            
            print(f"âœ… ë³‘ë ¬ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì™„ë£Œ")
            return state
            
        except Exception as e:
            print(f"âŒ ë³‘ë ¬ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            # í´ë°±ìœ¼ë¡œ ìˆœì°¨ ì‹¤í–‰
            return await self.workflow.ainvoke(state)
    
    def get_workflow_status(self) -> Dict[str, Any]:
        """ì›Œí¬í”Œë¡œìš° ìƒíƒœ ë°˜í™˜"""
        return {
            "workflow_type": "unified",
            "nodes_count": 6,
            "api_status": env_manager.get_api_status_summary(),
            "dependency_status": self.tools.validate_dependencies(),
            "error_summary": error_handler.get_error_summary(),
            "cache_metrics": enhanced_cache.get_metrics(),
            "parallel_processing_metrics": parallel_processor.get_metrics(),
            "timestamp": datetime.now().isoformat()
        }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
unified_workflow = UnifiedRequirementsWorkflow()
